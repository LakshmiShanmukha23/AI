{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68b1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4ef99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf2cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a642988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model=BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae3d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean.txt\",'r') as fp:\n",
    "    text=fp.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0657e8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.',\n",
       " 'From my great-grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally.',\n",
       " \"From my governor, to be neither of the green nor of the blue party at the games in the Circus, nor a partizan either of the Parmularius or the Scutarius at the gladiators' fights; from him too I learned endurance of labour, and to want little, and to work with my own hands, and not to meddle with other people's affairs, and not to be ready to listen to slander.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfacf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6a1ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4fbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(text[:8],padding=True,truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cad4cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153e78ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 240])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d8e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"labels\"]=inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c653fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand=torch.rand(inputs.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aba3fb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 240])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f565425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr=(rand<0.15)*(inputs.input_ids!=101)*(inputs.input_ids!=102)*(inputs.input_ids!=0)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19dc8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 240])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0000ac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11],\n",
       "        [12],\n",
       "        [14]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr[0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b87a421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=[]\n",
    "for i in range(len(mask_arr)):\n",
    "    ans.append(torch.flatten(mask_arr[i].nonzero()).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76aaffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mask_arr)):\n",
    "    inputs.input_ids[i,ans[i]]=103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3769ba7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2013,  4487,  ...,     0,     0,     0],\n",
       "        [  101,  2013, 27471,  ...,  3074,  1012,   102],\n",
       "        [  101,  2013,  9348,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20fc1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a514abf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "573f29e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.5577, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f8fe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 240, 30522])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6a41493",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=torch.nn.functional.softmax(outputs.logits,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b285ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=torch.argmax(score,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07f9a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=inputs.labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7e4a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=tokens[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4edceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "act=tokenizer.decode(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6d7c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From my great-grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d8555f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] from my great - grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19539ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred=tokenizer.decode(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a3c8f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". from my great personalness, not to have frequented public schools, and to have had no teachers at home, and to know that on such things a man should spend liberally....... and a no no no no them but too, not all all all all good agenesslylylyly attended. the, but not not no no no no too, but not know knowledge all such all such man shouldlylyly.lyly. in.ly, not he no no noly.lyly andly all all all such things should timelyly.ly.. '.. but i the time. i andly educationly and not to all money on such all such such things time he timenessly ; not to attended attended the,, not to not no no them no too, but not not even all such such all all good time timelylylylyly.ly.... on such such such no no i to no noly notlyly that even on all time all things shouldlylyly.ly.... '... aly..lyly.ly..'' but\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf3d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
