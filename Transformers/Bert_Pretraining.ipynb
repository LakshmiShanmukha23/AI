{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb2ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59cd03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer,BertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2ddbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model=BertForPreTraining.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8444b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean.txt\",'r') as fp:\n",
    "    text=fp.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24783e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29fc4a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.',\n",
       " 'From my great-grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally.',\n",
       " \"From my governor, to be neither of the green nor of the blue party at the games in the Circus, nor a partizan either of the Parmularius or the Scutarius at the gladiators' fights; from him too I learned endurance of labour, and to want little, and to work with my own hands, and not to meddle with other people's affairs, and not to be ready to listen to slander.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee2ec6",
   "metadata": {},
   "source": [
    "# NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafbfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag=[sentence for paragraph in text for sentence in paragraph.split(\".\") if sentence!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69f2e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b06991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a=[]\n",
    "sentence_b=[]\n",
    "label=[]\n",
    "\n",
    "for paragraph in text:\n",
    "    sentences=[\n",
    "        sentence for sentence in paragraph.split(\".\") if sentence!=''\n",
    "    ]\n",
    "    num_sentences=len(sentences)\n",
    "    if num_sentences>1:\n",
    "        start=random.randint(0,num_sentences-2)\n",
    "        sentence_a.append(sentences[start])\n",
    "        if random.random()>0.5:\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "            \n",
    "        else:\n",
    "            sentence_b.append(bag[random.randint(0,len(bag)-1)])\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15393b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 317, 317)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_a),len(sentence_b),len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ed3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence__a=sentence_a[:15]\n",
    "sentence__b=sentence_b[:15]\n",
    "ladel_=label[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07bc1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(sentence__a,sentence__b,padding=True,truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f0a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034a6e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([ladel_]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf094f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"next_sentence_label\"]=torch.LongTensor([ladel_]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b313ae1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.next_sentence_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afb37a",
   "metadata": {},
   "source": [
    "# MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20bfed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"labels\"]=inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329c59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random=torch.rand((inputs.input_ids.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b6ec298",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr=(random<0.15)*(inputs.input_ids!=101)*(inputs.input_ids!=102)*(inputs.input_ids!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea92eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27f3d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36e22213",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mask_arr)):\n",
    "    selection=torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    selected.append(selection)\n",
    "    inputs.input_ids[i,selection]=103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0676c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2013, 21692,  ...,     0,     0,     0],\n",
       "        [  101,  2002,  2165,  ...,     0,     0,     0],\n",
       "        [  101,  2582,  1010,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2023,  1010,  ...,     0,     0,     0],\n",
       "        [  101,  1998,  7065,  ...,     0,     0,     0],\n",
       "        [  101,  2295, 15223,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52a770",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a237d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7975d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e809518",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim=AdamW(model.parameters(),lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83e5b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46c580b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b6758a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74090ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.input_ids.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sample={\n",
    "            key : torch.Tensor(value[idx]) for key,value in self.data.items()\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bff4020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=CustomDataSet(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9020bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=torch.utils.data.DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7210ab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2acd1fcfa90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f62f6b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████| 1/1 [00:55<00:00, 55.68s/it, loss=11.9]\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████| 1/1 [01:12<00:00, 72.26s/it, loss=8.05]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs=2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    step=tqdm(loader,leave=True)\n",
    "    for batch in step:\n",
    "        optim.zero_grad()\n",
    "        input_ids=batch[\"input_ids\"]\n",
    "        attention_mask=batch[\"attention_mask\"]\n",
    "        next_sentence_label=batch[\"next_sentence_label\"]\n",
    "        token_type_ids=batch[\"token_type_ids\"]\n",
    "        labels=batch[\"labels\"]\n",
    "        op=model(input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,\n",
    "                 next_sentence_label=next_sentence_label,labels=labels)\n",
    "        loss=op.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        step.set_description(f\"Epoch {epoch}\")\n",
    "        step.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88401a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    opp=model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7a49c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3f40351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5477)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b9d500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147, 30522])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp.prediction_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab05fde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp.seq_relationship_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2339b6",
   "metadata": {},
   "source": [
    "# NSP outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ef47dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 1\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 1\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 1\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 1\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 1\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n",
      "actual: 1\n",
      "predicted: 1\n",
      "\n",
      "\n",
      "actual: 0\n",
      "predicted: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(opp.seq_relationship_logits)):\n",
    "    print(\"actual:\",inputs.next_sentence_label[i].item())\n",
    "    print(\"predicted:\",torch.argmax(opp.seq_relationship_logits[i]).item())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90676ef",
   "metadata": {},
   "source": [
    "# MLM outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b9d01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 12, 17, 18, 23, 24, 26, 28, 45, 56]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d3debfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e489ecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147, 30522])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp.prediction_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d4008e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ M A S K ]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs.input_ids[14,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e24454f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t e n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs.labels[14,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "880d9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=torch.nn.functional.softmax(opp.prediction_logits,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcb12724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.argmax(score,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5775900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 147])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e284a38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a s'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pred[14,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5c67b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5477)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0235f83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] though thou shouldst be going [MASK] live three thousand years [MASK] and as many times [MASK] [MASK] years, still remember [MASK] [MASK] man [MASK] any [MASK] life than this which he now lives, nor lives any other than this which he [MASK] loses [SEP] the longest and shortest are thus brought to [MASK] same [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs.input_ids[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "179db785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] though thou shouldst be going to live three thousand years, and as many times ten thousand years, still remember that no man loses any other life than this which he now lives, nor lives any other than this which he now loses [SEP] the longest and shortest are thus brought to the same [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs.labels[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46feb104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. though thou shouldst be going to live three thousand years, and as many times as thousand years, still remember no no man has any other life than this which he now lives, nor lives any other than this which he now loses. the longest and shortest are thus brought to the same. thout, to has he in,,, for many as three ten even he i shortest shortest no no shortest other other end the other in man to lives in has lives life life life life life life now now now thousand now now and which no no shortest has other other other life in which lives now loses, he lives life life, lives now now now now longest shortest shortest shortest shortest shortest no shortest shortest not not end life other the'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pred[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b4cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
