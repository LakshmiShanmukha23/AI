{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "023c3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "921c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9103ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e28fec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,LSTM,Input,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8295a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttentionWithMonotonic(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, method=\"Dot\", window_size=5):\n",
    "        super(LuongAttentionWithMonotonic, self).__init__()\n",
    "        self.method = method\n",
    "        self.window_size = window_size\n",
    "        self.w1 = Dense(units, use_bias=False)\n",
    "        if method == \"Concat\":\n",
    "            self.weight = tf.Variable(initial_value=tf.zeros((units, 1)), trainable=True, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_op, decoder_op, decoder_step = inputs\n",
    "        if self.method == \"General\":\n",
    "            decoder_op = tf.transpose(decoder_op, perm=(0, 2, 1))\n",
    "            ou1 = self.w1(encoder_op)\n",
    "            score = tf.matmul(ou1, decoder_op)\n",
    "\n",
    "        elif self.method == \"Dot\":\n",
    "            decoder_op = tf.transpose(decoder_op, perm=(0, 2, 1))\n",
    "            score = tf.matmul(encoder_op, decoder_op)\n",
    "\n",
    "        elif self.method == \"Concat\":\n",
    "            concat = tf.nn.tanh(self.w1(encoder_op) + self.w1(decoder_op))\n",
    "            score = tf.matmul(concat, self.weight)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                raise ValueError(\"Try valid alignment\")\n",
    "            except ValueError as e:\n",
    "                print(\"Error:\", e)\n",
    "                return\n",
    "\n",
    "        pt = tf.cast(decoder_step, tf.int32)  \n",
    "        pt_minus_D = tf.maximum(pt - self.window_size, 0)  \n",
    "        pt_plus_D = tf.minimum(pt + self.window_size + 1, tf.shape(encoder_op)[1])  \n",
    "\n",
    "        mask = tf.sequence_mask([pt_minus_D, pt_plus_D],\n",
    "                                maxlen=tf.shape(encoder_op)[1], dtype=tf.float32)\n",
    "\n",
    "        score = score * mask\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = tf.matmul(attention_weights, encoder_op)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "144ff39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttentionWithLocalWindow(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, method=\"Dot\", window_size=5):\n",
    "        super(LuongAttentionWithLocalWindow, self).__init__()\n",
    "        self.method = method\n",
    "        self.window_size = window_size\n",
    "        self.w1 = Dense(units, use_bias=False)\n",
    "        self.v = Dense(units, use_bias=False)  \n",
    "\n",
    "        if method == \"Concat\":\n",
    "            self.weight = tf.Variable(initial_value=tf.zeros((units, 1)), trainable=True, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_op, decoder_op, decoder_step = inputs\n",
    "\n",
    "        pt = decoder_step * tf.sigmoid(self.v(tf.nn.tanh(self.w1(decoder_op))))\n",
    "\n",
    "        sigma = self.window_size / 2.0\n",
    "        alpha = tf.exp(-0.5 * tf.square(tf.expand_dims(tf.range(tf.shape(encoder_op)[1]), axis=0) - \n",
    "                                        tf.expand_dims(pt, axis=1)) / tf.square(sigma))\n",
    "        mask = tf.sequence_mask([tf.cast(tf.round(pt - self.window_size / 2), tf.int32),\n",
    "                                 tf.cast(tf.round(pt + self.window_size / 2) + 1, tf.int32)],\n",
    "                                maxlen=tf.shape(encoder_op)[1], dtype=tf.float32)\n",
    "\n",
    "        score = self.score(encoder_op, decoder_op)  \n",
    "        score = score * alpha * mask\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = tf.matmul(attention_weights, encoder_op)\n",
    "        return context_vector\n",
    "\n",
    "    def score(self, encoder_op, decoder_op):\n",
    "        if self.method == \"General\":\n",
    "            decoder_op = tf.transpose(decoder_op, perm=(0, 2, 1))\n",
    "            ou1 = self.w1(encoder_op)\n",
    "            score = tf.matmul(ou1, decoder_op)\n",
    "\n",
    "        elif self.method == \"Dot\":\n",
    "            decoder_op = tf.transpose(decoder_op, perm=(0, 2, 1))\n",
    "            score = tf.matmul(encoder_op, decoder_op)\n",
    "\n",
    "        elif self.method == \"Concat\":\n",
    "            concat = tf.nn.tanh(self.w1(encoder_op) + self.w1(decoder_op))\n",
    "            score = tf.matmul(concat, self.weight)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                raise ValueError(\"Try valid alignment\")\n",
    "            except ValueError as e:\n",
    "                print(\"Error:\", e)\n",
    "                return\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a4d12c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a715b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional,Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "34c775f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongGlobalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,method=\"Dot\"):\n",
    "        super(LuongGlobalAttention,self).__init__()\n",
    "        self.method=method\n",
    "        self.w1=Dense(units,use_bias=False)\n",
    "        if method==\"Concat\":\n",
    "            self.weight = tf.Variable(initial_value=tf.zeros((units,1)), trainable=True, dtype=tf.float32)\n",
    "            \n",
    "    def call(self,inputs):\n",
    "        encoder_op,decoder_op=inputs\n",
    "        if self.method==\"General\":\n",
    "            decoder_op=tf.transpose(decoder_op,perm=(0,2,1))\n",
    "            ou1=self.w1(encoder_op)\n",
    "            score=tf.matmul(ou1,decoder_op)\n",
    "            \n",
    "        elif self.method==\"Dot\":\n",
    "            decoder_op=tf.transpose(decoder_op,perm=(0,2,1))\n",
    "            score=tf.matmul(encoder_op,decoder_op)\n",
    "            \n",
    "        elif self.method==\"Concat\":\n",
    "            concat=tf.nn.tanh(self.w1(encoder_op)+self.w1(decoder_op))\n",
    "            score=tf.matmul(concat,self.weight)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                raise ValueError(\"Try valid alignment\")\n",
    "            except ValueError as e:\n",
    "                print(\"Error:\", e)\n",
    "                return\n",
    "            \n",
    "        attention_weights=tf.nn.softmax(score,axis=1)\n",
    "        attention_weights=tf.transpose(attention_weights,perm=(0,2,1))\n",
    "        context_vector=tf.matmul(attention_weights,encoder_op)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "647a2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_len=10\n",
    "ip_vocab_size=2\n",
    "tg_vocab_size=5\n",
    "lstm_units=15\n",
    "embed_dim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "41ff1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input=Input(shape=(src_len,))\n",
    "decoder_input=Input(shape=(None,))\n",
    "\n",
    "encoder_embedding=Embedding(ip_vocab_size,embed_dim)\n",
    "decoder_embedding=Embedding(tg_vocab_size,embed_dim)\n",
    "\n",
    "encoder_embed=encoder_embedding(encoder_input)\n",
    "decoder_embed=decoder_embedding(decoder_input)\n",
    "\n",
    "encoder_lstm=Bidirectional(LSTM(lstm_units,return_sequences=True,return_state=True))\n",
    "encoder_op,forward_h,forward_c,backward_h,backward_c=encoder_lstm(encoder_embed)\n",
    "encoder_dense=Dense(lstm_units)\n",
    "h=tf.concat([forward_h,backward_h],axis=-1)\n",
    "c=tf.concat([forward_c,backward_c],axis=-1)\n",
    "encoder_op=encoder_dense(encoder_op)\n",
    "h=encoder_dense(h)\n",
    "c=encoder_dense(c)\n",
    "\n",
    "decoder_lstm=LSTM(lstm_units,return_sequences=True,return_state=True)\n",
    "decoder_op,h1,c1=decoder_lstm(decoder_embed,initial_state=[h,c])\n",
    "attention=LuongGlobalAttention(lstm_units,method=\"General\")\n",
    "context_vector=attention([encoder_op,decoder_op])\n",
    "\n",
    "decoder_op=tf.concat([context_vector, decoder_op],axis=-1)\n",
    "decoder_op=tf.nn.tanh(decoder_op)\n",
    "decoder_dense=Dense(tg_vocab_size,activation='softmax')\n",
    "decoder_op=decoder_dense(decoder_op)\n",
    "\n",
    "model=Model([encoder_input,decoder_input],[decoder_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "df8836d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=np.random.random((30,10))\n",
    "outputs=np.random.random((30,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e70eabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "757296b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(inputs,outputs,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7fa7610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot=tf.one_hot(y_train,tg_vocab_size)\n",
    "y_test_onehot=tf.one_hot(y_test,tg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "540910be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24, 7), TensorShape([24, 7, 5]))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "602a2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b26fd478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 15s 642ms/step - loss: 1.5934 - accuracy: 0.3750 - val_loss: 1.5413 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.5091 - accuracy: 1.0000 - val_loss: 1.4564 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.4215 - accuracy: 1.0000 - val_loss: 1.3626 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x272924eb430>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train,y_train],y_train_onehot,epochs=3,batch_size=5,validation_data=([X_test,y_test],y_test_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "da96b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_77 (InputLayer)       [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_76 (Embedding)    (None, 10, 20)               40        ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional_12 (Bidirect  [(None, 10, 30),             4320      ['embedding_76[0][0]']        \n",
      " ional)                       (None, 15),                                                         \n",
      "                              (None, 15),                                                         \n",
      "                              (None, 15),                                                         \n",
      "                              (None, 15)]                                                         \n",
      "                                                                                                  \n",
      " input_78 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " tf.concat_39 (TFOpLambda)   (None, 30)                   0         ['bidirectional_12[0][1]',    \n",
      "                                                                     'bidirectional_12[0][3]']    \n",
      "                                                                                                  \n",
      " tf.concat_40 (TFOpLambda)   (None, 30)                   0         ['bidirectional_12[0][2]',    \n",
      "                                                                     'bidirectional_12[0][4]']    \n",
      "                                                                                                  \n",
      " dense_52 (Dense)            multiple                     465       ['bidirectional_12[0][0]',    \n",
      "                                                                     'tf.concat_39[0][0]',        \n",
      "                                                                     'tf.concat_40[0][0]']        \n",
      "                                                                                                  \n",
      " embedding_77 (Embedding)    (None, None, 20)             100       ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_72 (LSTM)              [(None, None, 15),           2160      ['embedding_77[0][0]',        \n",
      "                              (None, 15),                            'dense_52[1][0]',            \n",
      "                              (None, 15)]                            'dense_52[2][0]']            \n",
      "                                                                                                  \n",
      " luong_global_attention_28   (None, None, 15)             225       ['dense_52[0][0]',            \n",
      " (LuongGlobalAttention)                                              'lstm_72[0][0]']             \n",
      "                                                                                                  \n",
      " tf.concat_41 (TFOpLambda)   (None, None, 30)             0         ['luong_global_attention_28[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'lstm_72[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.tanh_21 (TFOpLambd  (None, None, 30)             0         ['tf.concat_41[0][0]']        \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)            (None, None, 5)              155       ['tf.math.tanh_21[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7465 (29.16 KB)\n",
      "Trainable params: 7465 (29.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6f380b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_input,[encoder_op,h,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d482178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_77 (InputLayer)       [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_76 (Embedding)    (None, 10, 20)               40        ['input_77[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional_12 (Bidirect  [(None, 10, 30),             4320      ['embedding_76[0][0]']        \n",
      " ional)                       (None, 15),                                                         \n",
      "                              (None, 15),                                                         \n",
      "                              (None, 15),                                                         \n",
      "                              (None, 15)]                                                         \n",
      "                                                                                                  \n",
      " tf.concat_39 (TFOpLambda)   (None, 30)                   0         ['bidirectional_12[0][1]',    \n",
      "                                                                     'bidirectional_12[0][3]']    \n",
      "                                                                                                  \n",
      " tf.concat_40 (TFOpLambda)   (None, 30)                   0         ['bidirectional_12[0][2]',    \n",
      "                                                                     'bidirectional_12[0][4]']    \n",
      "                                                                                                  \n",
      " dense_52 (Dense)            multiple                     465       ['bidirectional_12[0][0]',    \n",
      "                                                                     'tf.concat_39[0][0]',        \n",
      "                                                                     'tf.concat_40[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4825 (18.85 KB)\n",
      "Trainable params: 4825 (18.85 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "98441df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model=Model([decoder_input,encoder_op,h,c],[decoder_op,h1,c1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "eac4bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_78 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_77 (Embedding)    (None, None, 20)             100       ['input_78[0][0]']            \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)       [(None, 15)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_81 (InputLayer)       [(None, 15)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_79 (InputLayer)       [(None, 10, 15)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_72 (LSTM)              [(None, None, 15),           2160      ['embedding_77[1][0]',        \n",
      "                              (None, 15),                            'input_80[0][0]',            \n",
      "                              (None, 15)]                            'input_81[0][0]']            \n",
      "                                                                                                  \n",
      " luong_global_attention_28   (None, None, 15)             225       ['input_79[0][0]',            \n",
      " (LuongGlobalAttention)                                              'lstm_72[1][0]']             \n",
      "                                                                                                  \n",
      " tf.concat_41 (TFOpLambda)   (None, None, 30)             0         ['luong_global_attention_28[1]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'lstm_72[1][0]']             \n",
      "                                                                                                  \n",
      " tf.math.tanh_21 (TFOpLambd  (None, None, 30)             0         ['tf.concat_41[1][0]']        \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)            (None, None, 5)              155       ['tf.math.tanh_21[1][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2640 (10.31 KB)\n",
      "Trainable params: 2640 (10.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bd5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
