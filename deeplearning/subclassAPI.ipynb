{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f35923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa07c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c28f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70367df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English example sentences\n",
    "english_texts = [\n",
    "    \"I love natural language processing.\",\n",
    "    \"TensorFlow is a powerful framework.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"This is an example text.\",\n",
    "    \"Neural networks are amazing.\",\n",
    "    \"AI is the future of technology.\"\n",
    "]\n",
    "\n",
    "# French example sentences (translations of English sentences)\n",
    "french_texts = [\n",
    "    \"J'adore le traitement du langage naturel.\",\n",
    "    \"TensorFlow est un cadre puissant.\",\n",
    "    \"L'apprentissage automatique est fascinant.\",\n",
    "    \"Ceci est un exemple de texte.\",\n",
    "    \"Les r√©seaux neuronaux sont incroyables.\",\n",
    "    \"L'IA est l'avenir de la technologie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e7f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the English and French sentences separately with OOV token\n",
    "english_tokenizer = Tokenizer(oov_token=\"UNK\")\n",
    "english_tokenizer.fit_on_texts(english_texts)\n",
    "english_word_index = english_tokenizer.word_index\n",
    "\n",
    "french_tokenizer = Tokenizer(oov_token=\"UNK\")\n",
    "french_tokenizer.fit_on_texts(french_texts)\n",
    "french_word_index = french_tokenizer.word_index\n",
    "\n",
    "# Convert text data to sequences of integers\n",
    "english_sequences = english_tokenizer.texts_to_sequences(english_texts)\n",
    "french_sequences = french_tokenizer.texts_to_sequences(french_texts)\n",
    "\n",
    "# Pad sequences to have the same length for modeling\n",
    "max_sequence_length = 8\n",
    "english_padded_sequences = pad_sequences(english_sequences, maxlen=max_sequence_length)\n",
    "french_padded_sequences = pad_sequences(french_sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a3ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_word_index[\"start\"]=len(french_word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c28d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9373671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(tf.keras.Model):\n",
    "    def __init__(self,i_vocab_size,t_vocab_size,embedding_dim,max_sequence_length):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding_layer1 = tf.keras.layers.Embedding(i_vocab_size, embedding_dim, input_length=max_sequence_length)\n",
    "        self.lstm1 = LSTM(10,return_sequences=True,return_state=True)\n",
    "        self.embedding_layer2 = tf.keras.layers.Embedding(t_vocab_size, embedding_dim, input_length=max_sequence_length)\n",
    "        self.lstm2 = LSTM(10,return_sequences=True,return_state=True)\n",
    "        self.dense_layer = tf.keras.layers.Dense(t_vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        e_inp,d_inp=inputs\n",
    "        x = self.embedding_layer1(e_inp)\n",
    "        e_op,h,c= self.lstm1(x)\n",
    "        y = self.embedding_layer2(d_inp)\n",
    "        d_op,h1,c1= self.lstm2(y,initial_state=[h,c])\n",
    "        output = self.dense_layer(d_op)\n",
    "        return output\n",
    "\n",
    "\n",
    "embedding_dim = 8\n",
    "t_vocab_size = len(french_word_index) + 1\n",
    "i_vocab_size=len(english_word_index)+1\n",
    "\n",
    "model = TextClassificationModel(i_vocab_size,t_vocab_size,embedding_dim,max_sequence_length)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51f0c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_one_hot=tf.one_hot(french_padded_sequences,depth=t_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f611b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3994 - accuracy: 0.0417\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.3976 - accuracy: 0.0833\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.3957 - accuracy: 0.2292\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3939 - accuracy: 0.3333\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.3920 - accuracy: 0.3542\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.3901 - accuracy: 0.3333\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3882 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x217a3adea70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([english_padded_sequences, french_padded_sequences],french_one_hot,\n",
    "          epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55791ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_classification_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     multiple                  224       \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               multiple                  760       \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     multiple                  240       \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               multiple                  760       \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2314 (9.04 KB)\n",
      "Trainable params: 2314 (9.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d391a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_french_word = french_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2e28b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_english_word = english_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bbbcb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_english_text = \"The application of AI in robotics is fascinating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fa08bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_english_sequence = english_tokenizer.texts_to_sequences([new_english_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c154f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_english_padded_sequences = pad_sequences(new_english_sequence, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6602e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_seq=np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ba21267",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_seq[0,0]=french_word_index[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ecdaea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "624643cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "translated_french_sequences = model.predict([new_english_padded_sequences,tar_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fbcf4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03434602, 0.03346131, 0.03403141, 0.03376238, 0.03365267,\n",
       "         0.03312952, 0.03314159, 0.03334253, 0.03353604, 0.03329704,\n",
       "         0.03338773, 0.03333544, 0.03325678, 0.03292664, 0.03323413,\n",
       "         0.03326814, 0.0330774 , 0.03296291, 0.03292364, 0.03338081,\n",
       "         0.033292  , 0.03309099, 0.03320865, 0.03360784, 0.03321854,\n",
       "         0.03340982, 0.03349654, 0.03279203, 0.03320983, 0.03321964]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_french_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d0d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03434602, 0.03346131, 0.03403141, 0.03376238, 0.03365267,\n",
       "        0.03312952, 0.03314159, 0.03334253, 0.03353604, 0.03329704,\n",
       "        0.03338773, 0.03333544, 0.03325678, 0.03292664, 0.03323413,\n",
       "        0.03326814, 0.0330774 , 0.03296291, 0.03292364, 0.03338081,\n",
       "        0.033292  , 0.03309099, 0.03320865, 0.03360784, 0.03321854,\n",
       "        0.03340982, 0.03349654, 0.03279203, 0.03320983, 0.03321964]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_french_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdf9afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_french_text = french_tokenizer.sequences_to_texts(translated_french_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b98e157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_french_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fcb5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
