{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1a90b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "129721b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51ed8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a4c6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40384058",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "data_file = open('spa.txt', encoding='utf-8')\n",
    "\n",
    "count = 0\n",
    "for line in data_file:\n",
    "    count += 1\n",
    "    if count > 20000:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    ip, temp_op, extra = line.rstrip().split('\\t')\n",
    "    op = temp_op\n",
    "    inputs.append(ip)\n",
    "    outputs.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf02aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[sentence.lower() for sentence in inputs]\n",
    "outputs=[sentence.lower() for sentence in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "168ae77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['<start> '+sentence+' <end>' for sentence in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d9607ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnglishTokenizer=Tokenizer(oov_token=\"<UNK>\")\n",
    "EnglishTokenizer.fit_on_texts(inputs)\n",
    "inp_sequences=EnglishTokenizer.texts_to_sequences(inputs)\n",
    "max_inp_len=max(len(i) for i in inp_sequences)\n",
    "src_sequences=pad_sequences(inp_sequences,maxlen=max_inp_len,padding=\"post\")\n",
    "Englishword2index=EnglishTokenizer.word_index\n",
    "Englishindex2word=EnglishTokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "faee3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpanishTokenizer=Tokenizer(oov_token=\"<UNK>\")\n",
    "SpanishTokenizer.fit_on_texts(outputs)\n",
    "op_sequences=SpanishTokenizer.texts_to_sequences(outputs)\n",
    "max_tar_len=max(len(i) for i in op_sequences)\n",
    "tar_sequences=pad_sequences(op_sequences,maxlen=max_tar_len,padding=\"post\")\n",
    "Spanishword2index=SpanishTokenizer.word_index\n",
    "Spanishindex2word=SpanishTokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79002790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_vocab_size: 3771\n",
      "tar_vocab_size: 7853\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size=len(Englishword2index)+1\n",
    "trg_vocab_size=len(Spanishword2index)+1\n",
    "print(\"src_vocab_size:\",src_vocab_size)\n",
    "print(\"tar_vocab_size:\",trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ef7b020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_inp_len: 6\n",
      "max_tar_len: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"max_inp_len:\",max_inp_len)\n",
    "print(\"max_tar_len:\",max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09c54f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units=100\n",
    "embed_dim=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "29a9c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Bidirectional,LSTM,Input,Embedding,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fbcaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongGlobalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,method=\"Dot\"):\n",
    "        super(LuongGlobalAttention,self).__init__()\n",
    "        self.method=method\n",
    "        self.w1=Dense(units,use_bias=False)\n",
    "        if method==\"Concat\":\n",
    "            self.weight = tf.Variable(initial_value=tf.zeros((units,1)), trainable=True, dtype=tf.float32)\n",
    "            \n",
    "    def call(self,inputs):\n",
    "        encoder_op,decoder_op=inputs\n",
    "        if self.method==\"General\":\n",
    "            decoder_op=tf.transpose(decoder_op,perm=(0,2,1))\n",
    "            ou1=self.w1(encoder_op)\n",
    "            score=tf.matmul(ou1,decoder_op)\n",
    "            \n",
    "        elif self.method==\"Dot\":\n",
    "            decoder_op=tf.transpose(decoder_op,perm=(0,2,1))\n",
    "            score=tf.matmul(encoder_op,decoder_op)\n",
    "            \n",
    "        elif self.method==\"Concat\":\n",
    "            concat=tf.nn.tanh(self.w1(encoder_op)+self.w1(decoder_op))\n",
    "            score=tf.matmul(concat,self.weight)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                raise ValueError(\"Try valid alignment\")\n",
    "            except ValueError as e:\n",
    "                print(\"Error:\", e)\n",
    "                return\n",
    "            \n",
    "        attention_weights=tf.nn.softmax(score,axis=1)\n",
    "        attention_weights=tf.transpose(attention_weights,perm=(0,2,1))\n",
    "        context_vector=tf.matmul(attention_weights,encoder_op)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e811fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input=Input(shape=(max_inp_len,))\n",
    "decoder_input=Input(shape=(None,))\n",
    "\n",
    "encoder_embedding=Embedding(src_vocab_size,embed_dim)\n",
    "decoder_embedding=Embedding(trg_vocab_size,embed_dim)\n",
    "\n",
    "encoder_embed=encoder_embedding(encoder_input)\n",
    "decoder_embed=decoder_embedding(decoder_input)\n",
    "\n",
    "encoder_lstm=Bidirectional(LSTM(lstm_units,return_sequences=True,return_state=True))\n",
    "encoder_op,forward_h,forward_c,backward_h,backward_c=encoder_lstm(encoder_embed)\n",
    "encoder_dense=Dense(lstm_units)\n",
    "h=tf.concat([forward_h,backward_h],axis=-1)\n",
    "c=tf.concat([forward_c,backward_c],axis=-1)\n",
    "encoder_op=encoder_dense(encoder_op)\n",
    "h=encoder_dense(h)\n",
    "c=encoder_dense(c)\n",
    "\n",
    "decoder_lstm=LSTM(lstm_units,return_sequences=True,return_state=True)\n",
    "decoder_op,h1,c1=decoder_lstm(decoder_embed,initial_state=[h,c])\n",
    "attention=LuongGlobalAttention(lstm_units,method=\"General\")\n",
    "context_vector=attention([encoder_op,decoder_op])\n",
    "\n",
    "decoder_op=tf.concat([context_vector, decoder_op],axis=-1)\n",
    "decoder_op=tf.nn.tanh(decoder_op)\n",
    "decoder_dense=Dense(trg_vocab_size,activation='softmax')\n",
    "decoder_op=decoder_dense(decoder_op)\n",
    "\n",
    "model=Model([encoder_input,decoder_input],[decoder_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8601542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 6, 200)               754200    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  [(None, 6, 200),             240800    ['embedding_2[0][0]']         \n",
      " onal)                        (None, 100),                                                        \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 200)                  0         ['bidirectional_1[0][1]',     \n",
      "                                                                     'bidirectional_1[0][3]']     \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)    (None, 200)                  0         ['bidirectional_1[0][2]',     \n",
      "                                                                     'bidirectional_1[0][4]']     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             multiple                     20100     ['bidirectional_1[0][0]',     \n",
      "                                                                     'tf.concat_3[0][0]',         \n",
      "                                                                     'tf.concat_4[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, None, 200)            1570600   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 100),          120400    ['embedding_3[0][0]',         \n",
      "                              (None, 100),                           'dense_3[1][0]',             \n",
      "                              (None, 100)]                           'dense_3[2][0]']             \n",
      "                                                                                                  \n",
      " luong_global_attention_1 (  (None, None, 100)            10000     ['dense_3[0][0]',             \n",
      " LuongGlobalAttention)                                               'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, None, 200)            0         ['luong_global_attention_1[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.tanh_1 (TFOpLambda  (None, None, 200)            0         ['tf.concat_5[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, None, 7853)           1578453   ['tf.math.tanh_1[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4294553 (16.38 MB)\n",
      "Trainable params: 4294553 (16.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7cb714bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 6), (20000, 14))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sequences.shape,tar_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f7f37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c93a48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(src_sequences,tar_sequences,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd772dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19000, 6), (1000, 6), (19000, 14), (1000, 14))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9e47b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ea72784",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_onehot=tf.one_hot(y_test,trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e542a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot=tf.one_hot(y_train,trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83dafe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "594/594 [==============================] - 204s 287ms/step - loss: 1.8422 - accuracy: 0.7610 - val_loss: 1.4164 - val_accuracy: 0.7887\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 151s 255ms/step - loss: 1.3494 - accuracy: 0.8054 - val_loss: 1.2611 - val_accuracy: 0.8248\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 173s 291ms/step - loss: 1.2104 - accuracy: 0.8359 - val_loss: 1.1389 - val_accuracy: 0.8511\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 148s 249ms/step - loss: 1.0971 - accuracy: 0.8552 - val_loss: 1.0393 - val_accuracy: 0.8626\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 163s 275ms/step - loss: 1.0147 - accuracy: 0.8637 - val_loss: 0.9747 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x211af268be0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train,y_train],y_train_onehot,batch_size=32,epochs=5,validation_data=([X_test,y_test],y_test_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "89a9c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"luong.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0639f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_input,[encoder_op,h,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d7bfe142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 6, 200)               754200    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  [(None, 6, 200),             240800    ['embedding_2[0][0]']         \n",
      " onal)                        (None, 100),                                                        \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 200)                  0         ['bidirectional_1[0][1]',     \n",
      "                                                                     'bidirectional_1[0][3]']     \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)    (None, 200)                  0         ['bidirectional_1[0][2]',     \n",
      "                                                                     'bidirectional_1[0][4]']     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             multiple                     20100     ['bidirectional_1[0][0]',     \n",
      "                                                                     'tf.concat_3[0][0]',         \n",
      "                                                                     'tf.concat_4[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1015100 (3.87 MB)\n",
      "Trainable params: 1015100 (3.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "350b0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model=Model([decoder_input,encoder_op,h,c],[decoder_op,h1,c1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2be2e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, None, 200)            1570600   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 6, 100)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 100),          120400    ['embedding_3[1][0]',         \n",
      "                              (None, 100),                           'input_9[0][0]',             \n",
      "                              (None, 100)]                           'input_10[0][0]']            \n",
      "                                                                                                  \n",
      " luong_global_attention_1 (  (None, None, 100)            10000     ['input_8[0][0]',             \n",
      " LuongGlobalAttention)                                               'lstm_3[1][0]']              \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, None, 200)            0         ['luong_global_attention_1[1][\n",
      "                                                                    0]',                          \n",
      "                                                                     'lstm_3[1][0]']              \n",
      "                                                                                                  \n",
      " tf.math.tanh_1 (TFOpLambda  (None, None, 200)            0         ['tf.concat_5[1][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, None, 7853)           1578453   ['tf.math.tanh_1[1][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3279453 (12.51 MB)\n",
      "Trainable params: 3279453 (12.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80fffbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 108ms/step - loss: 0.9747 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9746941924095154, 0.8709999918937683]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test,y_test],y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b806938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=inputs[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a7eb02a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tom tried.'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "14a7ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=EnglishTokenizer.texts_to_sequences([sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7c2952f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 425]]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a0f34839",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=pad_sequences(sequences,maxlen=max_inp_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "97e50178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "53e12e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_encoder(seq):\n",
    "    return encoder_model.predict(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ecf4f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_decoder(tar_seq, encoder_op, h, c):\n",
    "    return decoder_model.predict([tar_seq, encoder_op, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b1ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "encoder_op, h, c = predict_encoder(seq)\n",
    "stop_condition = False\n",
    "tar_seq = np.array([[Spanishword2index[\"start\"]]])\n",
    "\n",
    "while not stop_condition:\n",
    "    decoder_op, h1, c1 = predict_decoder(tar_seq, encoder_op, h, c)\n",
    "    index = np.argmax(decoder_op[0, -1, :])\n",
    "\n",
    "    char = Spanishindex2word.get(index, \"\")\n",
    "    \n",
    "    if char == 'end':\n",
    "        stop_condition = True\n",
    "    elif char != 'start':  \n",
    "        out1.append(char)\n",
    "\n",
    "    tar_seq = np.array([[index]])\n",
    "    h = h1\n",
    "    c = c1\n",
    "\n",
    "print(' '.join(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4239523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "start Â¿es ahora ahora eso eso eso\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "encoder_op, h, c = predict_encoder(seq)\n",
    "stop_condition = False\n",
    "tar_seq = np.array([[Spanishword2index[\"start\"]]])\n",
    "\n",
    "while not stop_condition:\n",
    "    decoder_op, h1, c1 = predict_decoder(tar_seq, encoder_op, h, c)\n",
    "    index = np.argmax(decoder_op[0, -1, :])\n",
    "    if index==0:\n",
    "        break\n",
    "    char = Spanishindex2word[index]\n",
    "    out1.append(char)\n",
    "\n",
    "    if char == 'end':\n",
    "        stop_condition = True\n",
    "\n",
    "    tar_seq = np.array([[index]])\n",
    "    h = h1\n",
    "    c = c1\n",
    "print(' '.join(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "635c7ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Beam Search Output: Â¿cÃ³mo Â¿cÃ³mo esto esto esto esto esto\n"
     ]
    }
   ],
   "source": [
    "def beam_search(encoder_model, decoder_model, seq, k=3):\n",
    "    def top_k_indices(predictions, k):\n",
    "        return np.argpartition(-predictions, k)[:k]\n",
    "\n",
    "    out = []\n",
    "    encoder_op, h, c = encoder_model.predict(seq)\n",
    "    stop_condition = False\n",
    "    tar_seq = np.array([[Spanishword2index[\"start\"]]])\n",
    "\n",
    "    while not stop_condition:\n",
    "        all_candidates = []\n",
    "        decoder_op, h1, c1 = decoder_model.predict([tar_seq, encoder_op, h, c])\n",
    "\n",
    "        # Get top-k indices for the next token\n",
    "        top_k = top_k_indices(decoder_op[0, -1, :], k)\n",
    "\n",
    "        for index in top_k:\n",
    "            word = Spanishindex2word.get(index, None)\n",
    "            if word is not None and word not in ['start', 'end']:\n",
    "                candidate_seq = out + [word]\n",
    "                candidate_prob = decoder_op[0, -1, index]\n",
    "                all_candidates.append((candidate_seq, candidate_prob))\n",
    "\n",
    "        # Sort candidates by probability (in decreasing order)\n",
    "        all_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Keep only the top-k candidates\n",
    "        all_candidates = all_candidates[:k]\n",
    "\n",
    "        # Update current output and check stop condition\n",
    "        out, next_prob = all_candidates[0]\n",
    "        if 'end' in out or len(out) > 6:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Prepare inputs for the next decoding step\n",
    "        tar_seq = np.array([[Spanishword2index[word] for word in out]])\n",
    "        h, c = h1, c1\n",
    "\n",
    "    return ' '.join(out)\n",
    "\n",
    "# Call the beam_search function with the encoder and decoder models\n",
    "beam_width = 3\n",
    "output_sequence = beam_search(encoder_model, decoder_model, seq, k=beam_width)\n",
    "print(\"Beam Search Output:\", output_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "94e2c313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> tomÃ¡s lo intentÃ³. <end>'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ac3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862baeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa31cc0",
   "metadata": {},
   "source": [
    "## Colab developed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb71202",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input=Input(shape=(max_inp_len,))\n",
    "decoder_input=Input(shape=(None,))\n",
    "\n",
    "encoder_embedding=Embedding(src_vocab_size,embed_dim)\n",
    "decoder_embedding=Embedding(trg_vocab_size,embed_dim)\n",
    "\n",
    "encoder_embed=encoder_embedding(encoder_input)\n",
    "decoder_embed=decoder_embedding(decoder_input)\n",
    "\n",
    "encoder_lstm=Bidirectional(LSTM(lstm_units,return_sequences=True,return_state=True))\n",
    "encoder_op,forward_h,forward_c,backward_h,backward_c=encoder_lstm(encoder_embed)\n",
    "encoder_dense=Dense(lstm_units)\n",
    "encoder_dropout=Dropout(rate=dropout_rate)\n",
    "h=tf.concat([forward_h,backward_h],axis=-1)\n",
    "c=tf.concat([forward_c,backward_c],axis=-1)\n",
    "encoder_op=encoder_dense(encoder_op)\n",
    "encoder_op=encoder_dropout(encoder_op)\n",
    "h=encoder_dense(h)\n",
    "c=encoder_dense(c)\n",
    "\n",
    "decoder_lstm=LSTM(lstm_units,return_sequences=True,return_state=True)\n",
    "decoder_op,h1,c1=decoder_lstm(decoder_embed,initial_state=[h,c])\n",
    "decoder_dropout=Dropout(rate=dropout_rate)\n",
    "decoder_op=decoder_dropout(decoder_op)\n",
    "attention=LuongGlobalAttention(lstm_units,method=\"General\")\n",
    "context_vector=attention([encoder_op,decoder_op])\n",
    "\n",
    "decoder_op=tf.concat([context_vector, decoder_op],axis=-1)\n",
    "decoder_op=tf.nn.tanh(decoder_op)\n",
    "decoder_dense=Dense(trg_vocab_size,activation='softmax')\n",
    "decoder_op=decoder_dense(decoder_op)\n",
    "\n",
    "model=Model([encoder_input,decoder_input],[decoder_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359efc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c43162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
