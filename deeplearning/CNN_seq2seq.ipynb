{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a427626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04106f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea5d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02b5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316158b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Embedding,Conv1D,Dense,Dropout,Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9208d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439e6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_inp_len=5\n",
    "max_tar_len=10\n",
    "embed_dim=100\n",
    "kernel_size=3\n",
    "padding=\"same\"\n",
    "hid_dim=200\n",
    "src_vocab_size=55\n",
    "trg_vocab_size=70\n",
    "drop_out=0.2\n",
    "scale=tf.sqrt(tf.constant(0.5))\n",
    "n_layers=3\n",
    "trg_pad_index=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bd27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,hid_dim,embed_dim,scale):\n",
    "        super(Attention,self).__init__()\n",
    "        self.hidden_embed=Dense(embed_dim)\n",
    "        self.embed_hidden=Dense(hid_dim)\n",
    "        self.scale=scale\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        decoder_embed,decoder_conv,encoder_conv,encoder_combined=inputs\n",
    "        \n",
    "        decoder_conved=self.hidden_embed(decoder_conv)\n",
    "        \n",
    "        decoder_combined=(decoder_conved+decoder_embed)*self.scale\n",
    "        \n",
    "        encoder_conv=tf.transpose(encoder_conv,perm=(0,2,1))\n",
    "        \n",
    "        energy=tf.matmul(decoder_combined,encoder_conv)\n",
    "        \n",
    "        attention_wts=tf.nn.softmax(energy,axis=1)\n",
    "        \n",
    "        context_vector=tf.matmul(attention_wts,encoder_combined)\n",
    "        \n",
    "        context_vector=self.embed_hidden(context_vector)\n",
    "        \n",
    "        context_vector_combined=(decoder_conv+context_vector)*self.scale\n",
    "        \n",
    "        return attention_wts,context_vector_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec94928",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_ip=Input(shape=(max_inp_len,))\n",
    "encoder_token_embed=Embedding(src_vocab_size,embed_dim)\n",
    "encoder_position_embed=Embedding(max_inp_len,embed_dim)\n",
    "encoder_dropout=Dropout(rate=drop_out)\n",
    "encoder_before_conv_dense=Dense(hid_dim)\n",
    "convs=[Conv1D(filters=2*hid_dim,kernel_size=kernel_size,padding=padding) for _ in range(n_layers)]\n",
    "encoder_after_conv_dense=Dense(embed_dim)\n",
    "\n",
    "encoder_token_embedding=encoder_token_embed(encoder_ip)\n",
    "\n",
    "#pos=Lambda(lambda x: tf.repeat(tf.range(0,max_inp_len),tf.shape(x)[0]))(encoder_ip)\n",
    "\n",
    "pos=tf.repeat(tf.range(0,max_inp_len),tf.shape(encoder_ip)[0])\n",
    "pos=tf.reshape(pos,(-1,max_inp_len))\n",
    "\n",
    "encoder_pos_embedding=encoder_position_embed(pos)\n",
    "\n",
    "encoder_embed_combined=encoder_token_embedding+encoder_pos_embedding\n",
    "\n",
    "encoder_embed_dropout=encoder_dropout(encoder_embed_combined)\n",
    "\n",
    "encoder_conv_ip=encoder_before_conv_dense(encoder_embed_dropout)\n",
    "\n",
    "for i,conv in enumerate(convs):\n",
    "    encoder_conv_dropout=encoder_dropout(encoder_conv_ip)\n",
    "    \n",
    "    encoder_conv=conv(encoder_conv_dropout)\n",
    "    \n",
    "    encoder_conv=tf.transpose(encoder_conv,perm=(0,2,1))\n",
    "    \n",
    "    conv_1,conv_2=tf.split(encoder_conv,num_or_size_splits=2,axis=1)\n",
    "    conv_1=sigmoid(conv_1)\n",
    "    encoder_conv=tf.multiply(conv_1,conv_2)\n",
    "    \n",
    "    encoder_conv=tf.transpose(encoder_conv,perm=(0,2,1))\n",
    "    \n",
    "    encoder_conv=(encoder_conv+encoder_conv_ip)*scale\n",
    "    encoder_conv_ip=encoder_conv\n",
    "    \n",
    "\n",
    "encoder_conv=encoder_after_conv_dense(encoder_conv)\n",
    "\n",
    "encoder_combined=(encoder_conv+encoder_embed_dropout)*scale\n",
    "\n",
    "\n",
    "decoder_ip=Input(shape=(max_tar_len,))\n",
    "decoder_token_embed=Embedding(src_vocab_size,embed_dim)\n",
    "decoder_position_embed=Embedding(max_tar_len,embed_dim)\n",
    "decoder_dropout=Dropout(rate=drop_out)\n",
    "decoder_before_conv_dense=Dense(hid_dim)\n",
    "convs1=[Conv1D(filters=2*hid_dim,kernel_size=kernel_size,padding=padding) for _ in range(n_layers)]\n",
    "\n",
    "attention=Attention(hid_dim,embed_dim,scale)\n",
    "\n",
    "decoder_after_conv_dense=Dense(embed_dim)\n",
    "decoder_dense=Dense(trg_vocab_size,activation=\"softmax\")\n",
    "\n",
    "decoder_token_embedding=decoder_token_embed(decoder_ip)\n",
    "\n",
    "pos1=tf.repeat(tf.range(0,max_tar_len),tf.shape(decoder_ip)[0])\n",
    "\n",
    "#pos1=Lambda(lambda x: tf.repeat(tf.range(0,max_tar_len),tf.shape(x)[0]))(decoder_ip)\n",
    "pos1=tf.reshape(pos1,(-1,max_tar_len))\n",
    "\n",
    "decoder_pos_embedding=decoder_position_embed(pos1)\n",
    "\n",
    "decoder_embed_combined=decoder_token_embedding+decoder_pos_embedding\n",
    "\n",
    "decoder_embed_dropout=decoder_dropout(decoder_embed_combined)\n",
    "\n",
    "decoder_conv_ip=decoder_before_conv_dense(decoder_embed_dropout)\n",
    "\n",
    "for j,conv1 in enumerate(convs1):\n",
    "    decoder_conv_dropout=decoder_dropout(decoder_conv_ip)\n",
    "    \n",
    "    padd=tf.fill((tf.shape(decoder_conv_ip)[0],decoder_conv_ip.shape[1],kernel_size-1),trg_pad_index)\n",
    "    \n",
    "    padd=tf.cast(padd,dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    padded_conv_ip=tf.concat((padd,decoder_conv_dropout),axis=-1)\n",
    "    \n",
    "    decoder_conv=conv1(padded_conv_ip)\n",
    "    \n",
    "    decoder_conv=tf.transpose(decoder_conv,perm=(0,2,1))\n",
    "    \n",
    "    conv_3,conv_4=tf.split(decoder_conv,num_or_size_splits=2,axis=1)\n",
    "    \n",
    "    conv_3=sigmoid(conv_3)\n",
    "    decoder_conv=tf.multiply(conv_3,conv_4)\n",
    "    \n",
    "    \n",
    "    decoder_conv=tf.transpose(decoder_conv,perm=(0,2,1))\n",
    "    \n",
    "    attention_wts,decoder_conv=attention([decoder_embed_dropout,decoder_conv,encoder_conv,encoder_combined])\n",
    "    \n",
    "    decoder_conv=(decoder_conv+decoder_conv_ip)*scale\n",
    "    decoder_conv_ip=decoder_conv\n",
    "    \n",
    "decoder_conv=decoder_after_conv_dense(decoder_conv)\n",
    "    \n",
    "decoder_conv_dropout=decoder_dropout(decoder_conv)\n",
    "    \n",
    "decoder_output=decoder_dense(decoder_conv_dropout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ec239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model([encoder_ip,decoder_ip],decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfec20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03b6a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.random.random((10,max_inp_len))\n",
    "y=np.random.random((10,max_tar_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56e1c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot=tf.one_hot(y,trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a214bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 10s 10s/step - loss: 4.2884 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.9633 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cdf6ca11e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X,y],y_one_hot,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c91bbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_ip,[encoder_conv,encoder_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b07fcbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input=Input(shape=(1,))\n",
    "encoder_conv1=Input(shape=(max_inp_len,embed_dim))\n",
    "encoder_com1=Input(shape=(max_inp_len,embed_dim))\n",
    "\n",
    "decoder_token_embedding1=decoder_token_embed(decoder_input)\n",
    "\n",
    "pos11=tf.repeat(tf.range(0,1),tf.shape(decoder_ip)[0])\n",
    "pos11=tf.reshape(pos11,(-1,1))\n",
    "\n",
    "decoder_pos_embedding1=decoder_position_embed(pos11)\n",
    "\n",
    "decoder_pos_embedding1=decoder_position_embed(pos11)\n",
    "decoder_embed_combined1=decoder_token_embedding1+decoder_pos_embedding1\n",
    "\n",
    "decoder_embed_dropout1=decoder_dropout(decoder_embed_combined1)\n",
    "\n",
    "decoder_conv_ip1=decoder_before_conv_dense(decoder_embed_dropout1)\n",
    "\n",
    "for j,conv1 in enumerate(convs1):\n",
    "    decoder_conv_dropout1=decoder_dropout(decoder_conv_ip1)\n",
    "    \n",
    "    padd1=tf.fill((tf.shape(decoder_conv_ip1)[0],decoder_conv_ip.shape[1],kernel_size-1),trg_pad_index)\n",
    "    \n",
    "    padd1=tf.cast(padd1,dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    padded_conv_ip1=tf.concat((padd1,decoder_conv_dropout1),axis=-1)\n",
    "    \n",
    "    decoder_conv1=conv1(padded_conv_ip1)\n",
    "    \n",
    "    decoder_conv1=tf.transpose(decoder_conv1,perm=(0,2,1))\n",
    "    \n",
    "    conv_31,conv_41=tf.split(decoder_conv1,num_or_size_splits=2,axis=1)\n",
    "    \n",
    "    conv_31=sigmoid(conv_31)\n",
    "    decoder_conv=tf.multiply(conv_31,conv_41)\n",
    "    \n",
    "    \n",
    "    decoder_conv1=tf.transpose(decoder_conv,perm=(0,2,1))\n",
    "    \n",
    "    attention_wts1,decoder_conv1=attention([decoder_embed_dropout1,decoder_conv1,encoder_conv1,encoder_com1])\n",
    "    \n",
    "    decoder_conv1=(decoder_conv1+decoder_conv_ip1)*scale\n",
    "    decoder_conv_ip1=decoder_conv1\n",
    "    \n",
    "decoder_conv1=decoder_after_conv_dense(decoder_conv1)\n",
    "    \n",
    "decoder_conv_dropout1=decoder_dropout(decoder_conv1)\n",
    "    \n",
    "decoder_output1=decoder_dense(decoder_conv_dropout1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de344f2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\") at layer \"tf.compat.v1.shape_8\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m decoder_model\u001b[38;5;241m=\u001b[39m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_com\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattention_wts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:167\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[0;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:266\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:1142\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[1;32m-> 1142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following previous layers were accessed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1146\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1147\u001b[0m         )\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[0;32m   1149\u001b[0m     computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\") at layer \"tf.compat.v1.shape_8\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "decoder_model=Model([decoder_input,encoder_conv,encoder_com],[decoder_output,attention_wts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba062d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
