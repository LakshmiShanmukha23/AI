{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736ab4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b130b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Input,Bidirectional,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b30f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8215ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_inp_len=2\n",
    "max_tar_len=5\n",
    "inp_vocab_size=4\n",
    "trg_vocab_size=7\n",
    "lstm_units=8\n",
    "embed_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba67e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongGlobalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,method=\"Dot\"):\n",
    "        super(LuongGlobalAttention,self).__init__()\n",
    "        self.method=method\n",
    "        self.w1=Dense(units,use_bias=False)\n",
    "        if method==\"Concat\":\n",
    "            self.weight = tf.Variable(initial_value=tf.zeros((units,1)), trainable=True, dtype=tf.float32)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        encoder_op,decoder_op=inputs\n",
    "        if self.method==\"General\":\n",
    "            decoder_op=tf.transpose(decoder_op,perm=(0,2,1))\n",
    "            ou1=self.w1(encoder_op)\n",
    "            score=tf.matmul(ou1,decoder_op)\n",
    "\n",
    "        elif self.method==\"Dot\":\n",
    "            decoder_op=tf.transpose(decoder_op,perm=(0,2,1))\n",
    "            score=tf.matmul(encoder_op,decoder_op)\n",
    "\n",
    "        elif self.method==\"Concat\":\n",
    "            concat=tf.nn.tanh(self.w1(encoder_op)+self.w1(decoder_op))\n",
    "            score=tf.matmul(concat,self.weight)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                raise ValueError(\"Try valid alignment\")\n",
    "            except ValueError as e:\n",
    "                print(\"Error:\", e)\n",
    "                return\n",
    "\n",
    "        attention_weights=tf.nn.softmax(score,axis=1)\n",
    "        attention_weights=tf.transpose(attention_weights,perm=(0,2,1))\n",
    "        context_vector=tf.matmul(attention_weights,encoder_op)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "24d04e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs=Input(shape=(max_inp_len,))\n",
    "encoder_embedded=Embedding(inp_vocab_size,embed_size)\n",
    "encoder_embed=encoder_embedded(encoder_inputs)\n",
    "encoder_dropout=Dropout(rate=0.3)\n",
    "\n",
    "encoder_lstm1=Bidirectional(LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform'))\n",
    "encoder_lstm1_output,forward_h,forward_c,backward_h,backward_c=encoder_lstm1(encoder_embed)\n",
    "encoder_lstm1_output=encoder_dropout(encoder_lstm1_output)\n",
    "\n",
    "h=tf.concat([forward_h,backward_h],axis=-1)\n",
    "c=tf.concat([forward_c,backward_c],axis=-1)\n",
    "\n",
    "encoder_dense=Dense(lstm_units)\n",
    "\n",
    "h=encoder_dense(h)\n",
    "c=encoder_dense(c)\n",
    "\n",
    "\n",
    "encoder_lstm2=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "encoder_lstm2_output,h,c=encoder_lstm2(encoder_lstm1_output,initial_state=[h,c])\n",
    "encoder_lstm2_output=encoder_dropout(encoder_lstm2_output)\n",
    "\n",
    "encoder_lstm3=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "encoder_lstm3_output,h,c=encoder_lstm3(encoder_lstm2_output,initial_state=[h,c])\n",
    "encoder_lstm3_output=encoder_dropout(encoder_lstm3_output)\n",
    "\n",
    "encoder_lstm_combined=encoder_lstm2_output+encoder_lstm3_output\n",
    "\n",
    "encoder_lstm4=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "encoder_lstm4_output,h,c=encoder_lstm4(encoder_lstm_combined,initial_state=[h,c])\n",
    "encoder_lstm4_output=encoder_dropout(encoder_lstm4_output)\n",
    "\n",
    "decoder_inputs=Input(shape=(None,))\n",
    "decoder_embedded=Embedding(trg_vocab_size,embed_size)\n",
    "decoder_embed=decoder_embedded(decoder_inputs)\n",
    "decoder_dropout=Dropout(rate=0.3)\n",
    "\n",
    "decoder_lstm1=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "decoder_lstm1_output,h1,c1=decoder_lstm1(decoder_embed,initial_state=[h,c])\n",
    "decoder_lstm1_output=decoder_dropout(decoder_lstm1_output)\n",
    "\n",
    "decoder_lstm2=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "decoder_lstm2_output,h1,c1=decoder_lstm2(decoder_lstm1_output,initial_state=[h1,c1])\n",
    "decoder_lstm2_output=decoder_dropout(decoder_lstm2_output)\n",
    "\n",
    "\n",
    "decoder_lstm3=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "decoder_lstm3_output,h1,c1=decoder_lstm3(decoder_lstm2_output,initial_state=[h1,c1])\n",
    "decoder_lstm3_output=decoder_dropout(decoder_lstm3_output)\n",
    "\n",
    "\n",
    "decoder_lstm_combined=decoder_lstm2_output+decoder_lstm3_output\n",
    "\n",
    "decoder_lstm4=LSTM(lstm_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "decoder_lstm4_output,h1,c1=decoder_lstm4(decoder_lstm_combined,initial_state=[h1,c1])\n",
    "decoder_lstm4_output=decoder_dropout(decoder_lstm4_output)\n",
    "\n",
    "\n",
    "attention=LuongGlobalAttention(lstm_units,method=\"Dot\")\n",
    "context_vector=attention([encoder_lstm4_output,decoder_lstm4_output])\n",
    "\n",
    "decoder_op=tf.concat([context_vector, decoder_lstm4_output],axis=-1)\n",
    "decoder_op=tf.nn.tanh(decoder_op)\n",
    "decoder_dense=Dense(trg_vocab_size,activation='softmax')\n",
    "decoder_op=decoder_dense(decoder_op)\n",
    "\n",
    "model=Model([encoder_inputs,decoder_inputs],decoder_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "60dfb2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)     (None, 2, 15)                60        ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirecti  [(None, 2, 16),              1536      ['embedding_8[0][0]']         \n",
      " onal)                        (None, 8),                                                          \n",
      "                              (None, 8),                                                          \n",
      "                              (None, 8),                                                          \n",
      "                              (None, 8)]                                                          \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)   (None, 16)                   0         ['bidirectional_4[0][1]',     \n",
      "                                                                     'bidirectional_4[0][3]']     \n",
      "                                                                                                  \n",
      " tf.concat_15 (TFOpLambda)   (None, 16)                   0         ['bidirectional_4[0][2]',     \n",
      "                                                                     'bidirectional_4[0][4]']     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         multiple                     0         ['bidirectional_4[0][0]',     \n",
      "                                                                     'lstm_33[0][0]',             \n",
      "                                                                     'lstm_34[0][0]',             \n",
      "                                                                     'lstm_35[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 8)                    136       ['tf.concat_14[0][0]',        \n",
      "                                                                     'tf.concat_15[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)              [(None, 2, 8),               800       ['dropout_4[0][0]',           \n",
      "                              (None, 8),                             'dense_12[0][0]',            \n",
      "                              (None, 8)]                             'dense_12[1][0]']            \n",
      "                                                                                                  \n",
      " lstm_34 (LSTM)              [(None, 2, 8),               544       ['dropout_4[1][0]',           \n",
      "                              (None, 8),                             'lstm_33[0][1]',             \n",
      "                              (None, 8)]                             'lstm_33[0][2]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 2, 8)                 0         ['dropout_4[1][0]',           \n",
      " OpLambda)                                                           'dropout_4[2][0]']           \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_35 (LSTM)              [(None, 2, 8),               544       ['tf.__operators__.add_6[0][0]\n",
      "                              (None, 8),                            ',                            \n",
      "                              (None, 8)]                             'lstm_34[0][1]',             \n",
      "                                                                     'lstm_34[0][2]']             \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, None, 15)             105       ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_36 (LSTM)              [(None, None, 8),            768       ['embedding_9[0][0]',         \n",
      "                              (None, 8),                             'lstm_35[0][1]',             \n",
      "                              (None, 8)]                             'lstm_35[0][2]']             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, None, 8)              0         ['lstm_36[0][0]',             \n",
      "                                                                     'lstm_37[0][0]',             \n",
      "                                                                     'lstm_38[0][0]',             \n",
      "                                                                     'lstm_39[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_37 (LSTM)              [(None, None, 8),            544       ['dropout_5[0][0]',           \n",
      "                              (None, 8),                             'lstm_36[0][1]',             \n",
      "                              (None, 8)]                             'lstm_36[0][2]']             \n",
      "                                                                                                  \n",
      " lstm_38 (LSTM)              [(None, None, 8),            544       ['dropout_5[1][0]',           \n",
      "                              (None, 8),                             'lstm_37[0][1]',             \n",
      "                              (None, 8)]                             'lstm_37[0][2]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, None, 8)              0         ['dropout_5[1][0]',           \n",
      " OpLambda)                                                           'dropout_5[2][0]']           \n",
      "                                                                                                  \n",
      " lstm_39 (LSTM)              [(None, None, 8),            544       ['tf.__operators__.add_7[0][0]\n",
      "                              (None, 8),                            ',                            \n",
      "                              (None, 8)]                             'lstm_38[0][1]',             \n",
      "                                                                     'lstm_38[0][2]']             \n",
      "                                                                                                  \n",
      " luong_global_attention_4 (  (None, None, 8)              0         ['dropout_4[3][0]',           \n",
      " LuongGlobalAttention)                                               'dropout_5[3][0]']           \n",
      "                                                                                                  \n",
      " tf.concat_16 (TFOpLambda)   (None, None, 16)             0         ['luong_global_attention_4[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'dropout_5[3][0]']           \n",
      "                                                                                                  \n",
      " tf.math.tanh_4 (TFOpLambda  (None, None, 16)             0         ['tf.concat_16[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, None, 7)              119       ['tf.math.tanh_4[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6244 (24.39 KB)\n",
      "Trainable params: 6244 (24.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6aea5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.007,clipnorm=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7a862b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true,y_pred):\n",
    "    loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
    "    loss=loss_fn(y_true,y_pred)\n",
    "    mask=tf.cast(y_true!=0,loss.dtype)\n",
    "    loss*=mask\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b8c6e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(y_true,y_pred):\n",
    "    y_pred=tf.argmax(y_pred,axis=-1)\n",
    "    y_pred=tf.cast(y_pred,y_true.dtype)\n",
    "    match=tf.cast(y_pred==y_true,tf.float32)\n",
    "    mask=tf.cast(y_true!=0,tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1de1f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss=masked_loss,metrics=[masked_accuracy,masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "540d49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.random.random((10,max_inp_len))\n",
    "y=np.random.random((10,max_tar_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01124768",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.random.random((2,max_inp_len))\n",
    "y1=np.random.random((2,max_tar_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "860f519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_onehot=tf.one_hot(y1,trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ef327eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 7])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "509ceb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot=tf.one_hot(y,trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "de62ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 5, 7])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f95a57e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 51s 51s/step - loss: 1.0535 - masked_accuracy: 0.0000e+00 - masked_loss: 1.0535 - val_loss: 0.7759 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.7759\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8249 - masked_accuracy: 0.0000e+00 - masked_loss: 0.8249 - val_loss: 0.5843 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.5843\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6476 - masked_accuracy: 0.0000e+00 - masked_loss: 0.6476 - val_loss: 0.4253 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.4253\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5126 - masked_accuracy: 0.0000e+00 - masked_loss: 0.5126 - val_loss: 0.3048 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.3048\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x,y],y,epochs=4,validation_data=([x1,y1],y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "903767cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b1804a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x244100272e0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"],label='loss')\n",
    "plt.plot(history.history[\"val_loss\"],label='val_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"token\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "30907fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0383 - masked_accuracy: 0.0000e+00 - masked_loss: 0.0383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03825240582227707, 0.0, 0.03825240582227707]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x1,y1],y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "53044525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 40s 40s/step - loss: 0.4054 - masked_accuracy: 0.0000e+00 - masked_loss: 0.4054 - val_loss: 0.2899 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.2899\n",
      "1/1 [==============================] - 40s 40s/step - loss: 0.3982 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3982 - val_loss: 0.2759 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.2759\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x0000024284347640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3763 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3763WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x00000243094E37F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 42s 42s/step - loss: 0.3763 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3763 - val_loss: 0.2626 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.2626\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x00000243118A7BE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3306 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3306WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x000002431DA2E680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.3306 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3306 - val_loss: 0.2501 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.2501\n",
      "1/1 [==============================] - 46s 46s/step - loss: 0.3252 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3252 - val_loss: 0.2384 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.2384\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.3355 - masked_accuracy: 0.0000e+00 - masked_loss: 0.3355 - val_loss: 0.1699 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.1699\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.2487 - masked_accuracy: 0.0000e+00 - masked_loss: 0.2487 - val_loss: 0.1298 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.1298\n",
      "1/1 [==============================] - 53s 53s/step - loss: 0.2018 - masked_accuracy: 0.0000e+00 - masked_loss: 0.2018 - val_loss: 0.1033 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.1033\n",
      "1/1 [==============================] - 43s 43s/step - loss: 0.1699 - masked_accuracy: 0.0000e+00 - masked_loss: 0.1699 - val_loss: 0.0848 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0848\n",
      "1/1 [==============================] - 47s 47s/step - loss: 0.1355 - masked_accuracy: 0.0000e+00 - masked_loss: 0.1355 - val_loss: 0.0718 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0718\n",
      "1/1 [==============================] - 46s 46s/step - loss: 0.1219 - masked_accuracy: 0.0000e+00 - masked_loss: 0.1219 - val_loss: 0.0617 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0617\n",
      "1/1 [==============================] - 48s 48s/step - loss: 0.0999 - masked_accuracy: 0.0000e+00 - masked_loss: 0.0999 - val_loss: 0.0543 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0543\n",
      "1/1 [==============================] - 51s 51s/step - loss: 0.1026 - masked_accuracy: 0.0000e+00 - masked_loss: 0.1026 - val_loss: 0.0477 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0477\n",
      "1/1 [==============================] - 48s 48s/step - loss: 0.0854 - masked_accuracy: 0.0000e+00 - masked_loss: 0.0854 - val_loss: 0.0427 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0427\n",
      "1/1 [==============================] - 49s 49s/step - loss: 0.0954 - masked_accuracy: 0.0000e+00 - masked_loss: 0.0954 - val_loss: 0.0383 - val_masked_accuracy: 0.0000e+00 - val_masked_loss: 0.0383\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "adam_epochs = 5\n",
    "sgd_epochs = 10\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,clipnorm=5)\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.2,clipnorm=5)\n",
    "\n",
    "\n",
    "total_epochs = adam_epochs + sgd_epochs\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch < adam_epochs:\n",
    "        model.compile(optimizer=adam_optimizer, loss=masked_loss,metrics=[masked_accuracy,masked_loss])\n",
    "    else:\n",
    "        model.compile(optimizer=sgd_optimizer, loss=masked_loss,metrics=[masked_accuracy,masked_loss])  \n",
    "        \n",
    "    history=model.fit([x,y],y,epochs=1,validation_data=([x1,y1],y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
