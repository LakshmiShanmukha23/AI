{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a2ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffb34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8b30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af756bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb09ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_texts = [\n",
    "    \"I love natural language processing.\",\n",
    "    \"TensorFlow is a powerful framework.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"This is an example text.\",\n",
    "    \"Neural networks are amazing.\",\n",
    "    \"AI is the future of technology.\",\n",
    "    \"I love natural language processing.\",\n",
    "    \"TensorFlow is a powerful framework.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"This is an example text.\",\n",
    "    \"Neural networks are amazing.\",\n",
    "    \"AI is the future of technology.\",\n",
    "    \"I love natural language processing.\",\n",
    "    \"TensorFlow is a powerful framework.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"This is an example text.\",\n",
    "    \"Neural networks are amazing.\",\n",
    "    \"AI is the future of technology.\"\n",
    "    \n",
    "]\n",
    "\n",
    "# French example sentences (translations of English sentences)\n",
    "french_texts = [\n",
    "    \"J'adore le traitement du langage naturel.\",\n",
    "    \"TensorFlow est un cadre puissant.\",\n",
    "    \"L'apprentissage automatique est fascinant.\",\n",
    "    \"Ceci est un exemple de texte.\",\n",
    "    \"Les réseaux neuronaux sont incroyables.\",\n",
    "    \"L'IA est l'avenir de la technologie.\",\n",
    "    \"J'adore le traitement du langage naturel.\",\n",
    "    \"TensorFlow est un cadre puissant.\",\n",
    "    \"L'apprentissage automatique est fascinant.\",\n",
    "    \"Ceci est un exemple de texte.\",\n",
    "    \"Les réseaux neuronaux sont incroyables.\",\n",
    "    \"L'IA est l'avenir de la technologie.\",\n",
    "    \"J'adore le traitement du langage naturel.\",\n",
    "    \"TensorFlow est un cadre puissant.\",\n",
    "    \"L'apprentissage automatique est fascinant.\",\n",
    "    \"Ceci est un exemple de texte.\",\n",
    "    \"Les réseaux neuronaux sont incroyables.\",\n",
    "    \"L'IA est l'avenir de la technologie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0b13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tokenizer = Tokenizer(oov_token=\"UNK\")\n",
    "english_tokenizer.fit_on_texts(english_texts)\n",
    "english_word_index = english_tokenizer.word_index\n",
    "\n",
    "french_tokenizer = Tokenizer(oov_token=\"UNK\")\n",
    "french_tokenizer.fit_on_texts(french_texts)\n",
    "french_word_index = french_tokenizer.word_index\n",
    "\n",
    "# Convert text data to sequences of integers\n",
    "english_sequences = english_tokenizer.texts_to_sequences(english_texts)\n",
    "french_sequences = french_tokenizer.texts_to_sequences(french_texts)\n",
    "\n",
    "# Pad sequences to have the same length for modeling\n",
    "max_sequence_length = 8\n",
    "english_padded_sequences = pad_sequences(english_sequences, maxlen=max_sequence_length)\n",
    "french_padded_sequences = pad_sequences(french_sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510eeb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_word_index[\"start\"]=len(french_word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360d1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_word_index[\"end\"]=len(french_word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c79532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897ad3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(tf.keras.Model):\n",
    "    def __init__(self,i_vocab_size,t_vocab_size,embedding_dim,max_sequence_length):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding_layer1 = tf.keras.layers.Embedding(i_vocab_size, embedding_dim, input_length=max_sequence_length)\n",
    "        self.lstm1 = LSTM(10,return_sequences=True,return_state=True)\n",
    "        self.embedding_layer2 = tf.keras.layers.Embedding(t_vocab_size, embedding_dim, input_length=max_sequence_length)\n",
    "        self.lstm2 = LSTM(10,return_sequences=True,return_state=True)\n",
    "        self.dense_layer = tf.keras.layers.Dense(t_vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        e_inp,d_inp=inputs\n",
    "        x = self.embedding_layer1(e_inp)\n",
    "        e_op,h,c= self.lstm1(x)\n",
    "        y = self.embedding_layer2(d_inp)\n",
    "        d_op,h1,c1= self.lstm2(y,initial_state=[h,c])\n",
    "        output = self.dense_layer(d_op)\n",
    "        return output\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "t_vocab_size = len(french_word_index) + 1\n",
    "i_vocab_size=len(english_word_index)+1\n",
    "\n",
    "model = TextClassificationModel(i_vocab_size,t_vocab_size,embedding_dim,max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f75230",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f97af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.7,clipnorm=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263efa5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b06a70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_function(targets, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43dd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "341d792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 3.6079\n",
      "Epoch 2/10 - Loss: 2.3262\n",
      "Epoch 3/10 - Loss: 1.5869\n",
      "Epoch 4/10 - Loss: 1.3139\n",
      "Epoch 5/10 - Loss: 0.9162\n",
      "Epoch 6/10 - Loss: 0.5964\n",
      "Epoch 7/10 - Loss: 0.6393\n",
      "Epoch 8/10 - Loss: 0.5795\n",
      "Epoch 9/10 - Loss: 0.5765\n",
      "Epoch 10/10 - Loss: 0.8834\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    steps_per_epoch = len(english_padded_sequences) // batch_size\n",
    "\n",
    "    for step in range(steps_per_epoch):\n",
    "        start = step * batch_size\n",
    "        end = (step + 1) * batch_size\n",
    "\n",
    "        batch_inputs = english_padded_sequences[start:end]\n",
    "        batch_targets = french_padded_sequences[start:end]\n",
    "        loss = train_step([batch_inputs,batch_targets],batch_targets)\n",
    "        total_loss += loss\n",
    "\n",
    "    average_loss = total_loss / steps_per_epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304dbdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  2800      \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  4440      \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     multiple                  3100      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               multiple                  4440      \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  341       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15121 (59.07 KB)\n",
      "Trainable params: 15121 (59.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967525c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_english_texts = [\n",
    "    \"I like deep learning.\",\n",
    "    \"AI is changing the world.\",\n",
    "    \"natural language processing is exciting.\"\n",
    "]\n",
    "\n",
    "test_french_texts = [\n",
    "    \"J'aime l'apprentissage profond.\",\n",
    "    \"L'IA change le monde.\",\n",
    "    \"Le traitement du langage naturel est passionnant.\"\n",
    "]\n",
    "\n",
    "test_english_sequences = english_tokenizer.texts_to_sequences(test_english_texts)\n",
    "test_french_sequences = french_tokenizer.texts_to_sequences(test_french_texts)\n",
    "\n",
    "test_english_padded_sequences = pad_sequences(test_english_sequences, maxlen=max_sequence_length)\n",
    "test_french_padded_sequences = pad_sequences(test_french_sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a05b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=(max_sequence_length,))\n",
    "encoder_embedding = model.layers[0](encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = model.layers[1](encoder_embedding)\n",
    "encoder_model = tf.keras.Model(encoder_inputs, [encoder_outputs,state_h,state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22e6071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 8, 100)            2800      \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 8, 10),           4440      \n",
      "                              (None, 10),                        \n",
      "                              (None, 10)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7240 (28.28 KB)\n",
      "Trainable params: 7240 (28.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a79c0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = tf.keras.layers.Input(shape=(max_sequence_length,))\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(None,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(None,))\n",
    "decoder_state_inputs = tf.keras.layers.Input(shape=(max_sequence_length,None))\n",
    "decoder_embedding = model.layers[2](decoder_inputs)\n",
    "decoder_outputs, state_h, state_c = model.layers[3](decoder_embedding, \n",
    "                                                    initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "decoder_outputs = model.layers[4](decoder_outputs)\n",
    "decoder_model = tf.keras.Model([decoder_inputs] + [decoder_state_inputs,decoder_state_input_h, decoder_state_input_c], \n",
    "                               [decoder_outputs]+[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b7dac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 8, 100)               3100      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 8, 10),              4440      ['embedding_1[0][0]',         \n",
      "                              (None, None),                          'input_3[0][0]',             \n",
      "                              (None, None)]                          'input_4[0][0]']             \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 8, None)]            0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 8, 31)                341       ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7881 (30.79 KB)\n",
      "Trainable params: 7881 (30.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e4a0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_sequence(input_seq):\n",
    "    input_seq=np.expand_dims(input_seq,axis=0)\n",
    "    encoder_output, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.array([[french_word_index['start']]])\n",
    "    output_seq = []\n",
    "    stop_condition=False\n",
    "    while not stop_condition:\n",
    "        decoder_output, state_h1, state_c1 = decoder_model.predict([target_seq]+[encoder_output,state_h, state_c])\n",
    "\n",
    "        # Get the next token index (greedy decoding)\n",
    "        sampled_token_index = np.argmax(decoder_output[0, 0, :])\n",
    "        if sampled_token_index ==0:\n",
    "            break\n",
    "        if sampled_token_index == french_word_index['end'] or len(output_seq) >= max_sequence_length - 1:\n",
    "            stop_condition=True\n",
    "\n",
    "        output_seq.append(sampled_token_index)\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        state_h,state_c=state_h1,state_c1\n",
    "\n",
    "    return output_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "212f8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_index_word = english_tokenizer.index_word\n",
    "french_index_word = french_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "462f927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 5, 6, 7, 2, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_english_padded_sequences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da9b0975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "seq_gred=greedy_decode_sequence(test_english_padded_sequences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7243f1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 16, 16, 16, 16, 16, 16, 16]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_gred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49d34f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=\"\"\n",
    "for i in seq_gred:\n",
    "    l+=french_index_word[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f2b0d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fascinantfascinantfascinantfascinantfascinantfascinantfascinantfascinant'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e270c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_infer(input_seq, beam_width=3):\n",
    "    input_seq=np.expand_dims(input_seq,axis=0)\n",
    "    encoder_output, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.array([[french_word_index['start']]])\n",
    "\n",
    "    sequences = [{'seq': target_seq, 'prob': 1.0, 'state': [state_h, state_c]}]\n",
    "\n",
    "    for _ in range(max_sequence_length):\n",
    "        all_candidates = []\n",
    "\n",
    "        for seq in sequences:\n",
    "            target_seq, state = seq['seq'], seq['state']\n",
    "            decoder_output, state_h1, state_c1 = decoder_model.predict([target_seq]+[encoder_output,state])\n",
    "            top_k_indices = np.argsort(decoder_output[0, 0, :])[-beam_width:]\n",
    "\n",
    "            for idx in top_k_indices:\n",
    "                candidate_seq = np.array([[idx]])\n",
    "                candidate_prob = seq['prob'] * decoder_output[0, 0, idx]\n",
    "                all_candidates.append({'seq': candidate_seq, 'prob': candidate_prob, 'state': [state_h1, state_c1]})\n",
    "\n",
    "        ordered = sorted(all_candidates, key=lambda x: x['prob'], reverse=True)\n",
    "        sequences = ordered[:beam_width]\n",
    "\n",
    "    output_seq = sequences[0]['seq'][0]\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55d22fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "seq=beam_search_infer(test_english_padded_sequences[2],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "502f4c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edca665a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fascinant'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=\"\"\n",
    "for i in seq:\n",
    "    m+=french_index_word[i]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14e34c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def beam_search_infer2(input_seq, beam_width=3):\n",
    "    input_seq = np.expand_dims(input_seq, axis=0)\n",
    "    encoder_output, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.array([[french_word_index['start']]])\n",
    "\n",
    "    sequences = [{'seq': target_seq, 'prob': 1.0, 'state': [state_h, state_c]}]\n",
    "\n",
    "    for _ in range(max_sequence_length):\n",
    "        all_candidates = []\n",
    "\n",
    "        for seq in sequences:\n",
    "            target_seq, state = seq['seq'], seq['state']\n",
    "            decoder_output, state_h1, state_c1 = decoder_model.predict([target_seq] + [encoder_output, state])\n",
    "            log_probs = tf.math.log(decoder_output)  # Using log probabilities\n",
    "            top_k_values, top_k_indices = tf.math.top_k(log_probs[0, 0, :], k=beam_width)  # Get top-k indices\n",
    "\n",
    "            for idx in top_k_indices.numpy():  # Convert TensorFlow tensor to NumPy array\n",
    "                candidate_seq = np.array([[idx]])\n",
    "                candidate_prob = seq['prob'] * tf.math.exp(log_probs[0, 0, idx])  # Convert log prob back to normal prob\n",
    "                all_candidates.append({'seq': candidate_seq, 'prob': candidate_prob, 'state': [state_h1, state_c1]})\n",
    "\n",
    "        ordered = sorted(all_candidates, key=lambda x: x['prob'], reverse=True)\n",
    "        sequences = ordered[:beam_width]\n",
    "\n",
    "    output_seq = sequences[0]['seq'][0]\n",
    "\n",
    "    return output_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52e1a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "seq2=beam_search_infer2(test_english_padded_sequences[2],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8844da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426de231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
