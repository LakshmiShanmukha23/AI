{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8762afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31cfc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1374a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding,MultiHeadAttention,Dense,LayerNormalization,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "38899b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model):\n",
    "        super(FeedForward,self).__init__()\n",
    "        self.linear1=Dense(2048,activation=\"relu\")\n",
    "        self.linear2=Dense(d_model)\n",
    "        self.dropout=Dropout(rate=0.1)\n",
    "        \n",
    "    def call(self,x):\n",
    "        output=self.linear1(x)\n",
    "        output=self.dropout(output)\n",
    "        output=self.linear2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d1d9b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,max_inp_len,inp_vocab_size,d_model,n_heads):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.mha=MultiHeadAttention(num_heads=n_heads,key_dim=d_model)\n",
    "        self.layer_norm1=LayerNormalization()\n",
    "        self.dropout1=Dropout(rate=0.1)\n",
    "        self.feed_forward=FeedForward(d_model)\n",
    "        self.layer_norm2=LayerNormalization()\n",
    "        self.dropout2=Dropout(rate=0.1)\n",
    "        \n",
    "    def call(self,x,mask):\n",
    "        context_vector=self.mha(x,x)\n",
    "        norm1=self.layer_norm1(context_vector+x)\n",
    "        norm1=self.dropout1(norm1)\n",
    "        feed_output=self.feed_forward(norm1)\n",
    "        norm2=self.layer_norm2(feed_output+norm1)\n",
    "        norm2=self.dropout2(norm2)\n",
    "        return norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "889804de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,max_inp_len,inp_vocab_size,d_model,n_layers,n_heads):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.word_embedding=Embedding(inp_vocab_size,d_model,trainable=True)\n",
    "        self.position_embedding=Embedding(max_inp_len,d_model,trainable=True)\n",
    "        self.segment_embedding=Embedding(max_inp_len,d_model,trainable=True)\n",
    "        self.encoder_layer=[EncoderLayer(max_inp_len,inp_vocab_size,d_model,n_heads) \n",
    "                                                                          for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self,inputs,mask):\n",
    "        x,segment_ids=inputs\n",
    "        word_embeddings=self.word_embedding(x)\n",
    "        position_embeddings=self.position_embedding(tf.range(tf.shape(x)[-1]))\n",
    "        segment_embeddings=self.segment_embedding(segment_ids)\n",
    "        inputs=word_embeddings+position_embeddings+segment_embeddings\n",
    "        for layer in self.encoder_layer:\n",
    "            inputs=layer(inputs,mask)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ba69df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.Model):\n",
    "    def __init__(self,max_inp_len,inp_vocab_size,d_model,n_layers,n_heads):\n",
    "        super(BERT,self).__init__()\n",
    "        self.encoder=Encoder(max_inp_len,inp_vocab_size,d_model,n_layers,n_heads)\n",
    "        self.dense=Dense(1)\n",
    "        \n",
    "    def call(self,inputss):\n",
    "        inputs,mask=inputss\n",
    "        output=self.encoder(inputs,mask)\n",
    "        output=tf.reshape(output,(tf.shape(output)[0],tf.shape(output)[1]*tf.shape(output)[2]))\n",
    "        output=self.dense(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7a2bdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1=[\"Exercise is important for maintaining good health.\",\"The company launched a new smartphone model.\",\n",
    "            \"Plants need sunlight for photosynthesis.\",\"The chef prepared a delicious three-course meal.\",\n",
    "            \"Music has a profound impact on emotions.\",\"The cat chased the mouse through the garden.\",\n",
    "            \"Water boils at 100 degrees Celsius.\",\"The sun rises in the east.\",\n",
    "\"Rainforests are home to a diverse range of species.\",\"The novel's intricate plot kept readers on the edge of their seats.\",\n",
    "\"Social media platforms connect people from around the world.\",\"The artist used vibrant colors to create a captivating painting.\",\n",
    "\"Bees play a crucial role in pollinating flowers.\",\"The scientist conducted experiments to test her hypothesis.\",\n",
    "        \"Shakespeare is renowned for his sonnets and plays.\",\"Mozart was a prolific composer of classical music.\",\n",
    "        \"Climate change poses a significant global challenge.\",\"Meditation has been shown to reduce stress.\",\n",
    "        \"The company introduced a revolutionary cleaning product.\",\"Time management is essential for productivity.\",\n",
    "        \"The space probe discovered a distant exoplanet.\",\"Hurricanes can cause widespread damage.\",\n",
    "        \"The fashion industry sets new trends each season.\",\"Diamonds are precious gemstones.\",\n",
    "        \"The economy experienced a downturn last year.\",\"Volcanoes can erupt with destructive force.\",\n",
    "        \"The ocean tides are influenced by the moon's gravitational pull.\",\"Soccer is a widely played sport.\",\n",
    "        \"Penguins are flightless birds found in Antarctica.\",\"Apples are a popular fruit.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6340ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2=[\"Regular physical activity can improve cardiovascular fitness.\",\"Customers eagerly lined up outside stores to purchase it.\",\n",
    "            \"This process is essential for their growth and survival.\",\"The aroma wafted through the air, making mouths water.\",\n",
    "            \"Certain melodies can evoke nostalgia and joy.\",\"Its agile movements were a sight to behold.\",\n",
    "            \"This is a fundamental property of physics.\",\"It illuminates the horizon with a warm glow.\",\n",
    "            \"Conservation efforts aim to protect their fragile ecosystems.\",\"Unraveling its mysteries was a thrilling experience.\",\n",
    "            \"They facilitate communication and the sharing of ideas.\",\"Each brushstroke contributed to the overall masterpiece.\",\n",
    "            \"This process is vital for the reproduction of many plants.\",\"The results confirmed her predictions and led to new insights.\",\n",
    "            \"His works continue to be studied and performed worldwide.\",\"The software update improves system performance.\",\n",
    "            \"The children played in the park all afternoon.\",\"The architecture of the building is breathtaking.\",\n",
    "            \"The art exhibition will run until the end of the month.\",\"The museum exhibits a collection of ancient artifacts.\",\n",
    "            \"She is known for her expertise in astrophysics.\",\"Mathematics is a subject that requires practice.\",\n",
    "            \"I like to start my day with a cup of herbal tea.\",\"The seminar on renewable energy was informative.\",\n",
    "            \"The novel explores themes of love and betrayal.\",\"I enjoy hiking in the mountains on weekends.\",\n",
    "            \"The movie received rave reviews from critics.\",\"The recipe calls for fresh herbs and spices.\",\n",
    "            \"Learning a new language requires dedication.\",\"The conference is scheduled for next week.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4a734107",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentences=[]\n",
    "for i in range(len(sentences1)):\n",
    "    s=\"\"\n",
    "    s+=\"[CLS] \"+sentences1[i]+\" [SEP] \"+sentences2[i]+\" [SEP]\"\n",
    "    combined_sentences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9c227129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] Exercise is important for maintaining good health. [SEP] Regular physical activity can improve cardiovascular fitness. [SEP]',\n",
       " '[CLS] The company launched a new smartphone model. [SEP] Customers eagerly lined up outside stores to purchase it. [SEP]']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3f4bc14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3c511aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1daa6d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=np.expand_dims(np.array(labels).reshape(-1),1)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "15bc22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "65d193f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "08826b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class Tokenization:\n",
    "    def __init__(self):\n",
    "        self.tokenizer =Tokenizer(oov_token=\"<OOV>\")\n",
    "        self.tokenized_pairs = []\n",
    "        self.segment_ids = []\n",
    "        self.attention_masks = []\n",
    "        \n",
    "    def tokenize_and_mask(self,combined_pairs,mask_prob=0.15):\n",
    "        \n",
    "        sentences = [pair for pair in combined_pairs]\n",
    "        self.tokenizer.fit_on_texts(sentences)\n",
    "        \n",
    "        for combined_pair in combined_pairs:\n",
    "            # Tokenize combined sentence pair\n",
    "            tokens = self.tokenizer.texts_to_sequences([combined_pair])[0]\n",
    "\n",
    "            # Calculate segment IDs based on [SEP] tokens\n",
    "            sep_positions = [pos for pos, token in enumerate(tokens) if token == self.tokenizer.word_index[\"sep\"]]\n",
    "            seg_id = [0] * (sep_positions[0] + 1) + [1] * (len(tokens) - sep_positions[0] - 1)\n",
    "\n",
    "\n",
    "            # Masking\n",
    "            num_tokens = len(tokens)\n",
    "            num_masked = int(num_tokens * mask_prob)\n",
    "            masked_indices = random.sample(range(1, num_tokens - 1), num_masked)\n",
    "\n",
    "            masked_tokens = tokens.copy()\n",
    "            for idx in masked_indices:\n",
    "                if random.random() < 0.8:  # 80% of the time, replace with a random word from the vocabulary\n",
    "                    masked_tokens[idx] = random.choice(list(tokenizer.word_index.values()))\n",
    "\n",
    "                else:  # 20% of the time, keep the token unchanged\n",
    "                    pass\n",
    "\n",
    "\n",
    "                #if random.random() < 0.8:  # 80% of the time, replace with [MASK]\n",
    "                    #masked_tokens[idx] = tokenizer.word_index['[MASK]']\n",
    "\n",
    "                #elif random.random() < 0.5:  # 10% of the time, replace with random word\n",
    "                    #masked_tokens[idx] = random.choice(list(tokenizer.word_index.values()))\n",
    "\n",
    "            # Create attention mask\n",
    "            attn_mask = [1] * len(masked_tokens)\n",
    "\n",
    "            self.tokenized_pairs.append(masked_tokens)\n",
    "            self.segment_ids.append(seg_id)\n",
    "            self.attention_masks.append(attn_mask)\n",
    "            \n",
    "        max_length = max(len(tokens) for tokens in tokenized_pairs)\n",
    "        padded_pairs =pad_sequences(self.tokenized_pairs, maxlen=max_length, padding='post')\n",
    "        segment_ids =pad_sequences(self.segment_ids, maxlen=max_length, padding='post')\n",
    "        attention_mask = pad_sequences(self.attention_masks, maxlen=max_length, padding='post')\n",
    "\n",
    "\n",
    "        return padded_pairs, segment_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5ca9add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=Tokenization()\n",
    "tp,si,am=tok.tokenize_and_mask(combined_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0ecda87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 23), (30, 23), (30, 23))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.shape,si.shape,am.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "383bb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_inp_len=tp.shape[-1]\n",
    "vocab=tok.tokenizer.word_index\n",
    "inp_vocab_size=len(vocab)+1\n",
    "n_heads=2\n",
    "d_model=768\n",
    "n_layers=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4035a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert=BERT(max_inp_len,inp_vocab_size,d_model,n_layers,n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6eb16456",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[tp,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6863eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=bert([inputs,am])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dc850b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "56969bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_9 (Encoder)         multiple                  94784256  \n",
      "                                                                 \n",
      " dense_196 (Dense)           multiple                  17665     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94801921 (361.64 MB)\n",
      "Trainable params: 94801921 (361.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9ccf1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2815394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 49s 49s/step - loss: 6.4573 - accuracy: 0.5556 - val_loss: 15.2492 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 9s 9s/step - loss: 6.7774 - accuracy: 0.5556 - val_loss: 15.2492 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "H=bert.fit([inputs,am],label,epochs=2,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "53aac4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6538ff4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(H.history[\"loss\"],label=\"training_loss\")\n",
    "plt.plot(H.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe86337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf69724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37004242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec832f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcaf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fdb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c201fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98726d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0690124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc5395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14e9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188751b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ee3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd5b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad42449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd9122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da1397f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a81671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c3ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ba7c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model):\n",
    "        super(FeedForward,self).__init__()\n",
    "        self.linear1=Dense(2048,activation=\"relu\")\n",
    "        self.linear2=Dense(d_model)\n",
    "        self.dropout=Dropout(rate=0.1)\n",
    "        \n",
    "    def call(self,x):\n",
    "        output=self.linear1(x)\n",
    "        output=self.dropout(output)\n",
    "        output=self.linear2(output)\n",
    "        return output\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,max_inp_len,inp_vocab_size,d_model,n_heads):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.mha=MultiHeadAttention(num_heads=n_heads,key_dim=d_model)\n",
    "        self.layer_norm1=LayerNormalization()\n",
    "        self.dropout1=Dropout(rate=0.1)\n",
    "        self.feed_forward=FeedForward(d_model)\n",
    "        self.layer_norm2=LayerNormalization()\n",
    "        self.dropout2=Dropout(rate=0.1)\n",
    "        \n",
    "    def call(self,x,mask):\n",
    "        context_vector=self.mha(x,x)\n",
    "        norm1=self.layer_norm1(context_vector+x)\n",
    "        norm1=self.dropout1(norm1)\n",
    "        feed_output=self.feed_forward(norm1)\n",
    "        norm2=self.layer_norm2(feed_output+norm1)\n",
    "        norm2=self.dropout2(norm2)\n",
    "        return norm2\n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,max_inp_len,inp_vocab_size,d_model,n_layers,n_heads):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.embedding=Embedding(inp_vocab_size,d_model)\n",
    "        self.encoder_layer=[EncoderLayer(max_inp_len,inp_vocab_size,d_model,n_heads) \n",
    "                                                                          for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self,inputs,mask):\n",
    "        inputs=self.embedding(inputs)\n",
    "        for layer in self.encoder_layer:\n",
    "            inputs=layer(inputs,mask)\n",
    "        return inputs\n",
    "    \n",
    "class BERT(tf.keras.Model):\n",
    "    def __init__(self,max_inp_len,inp_vocab_size,d_model,n_layers,n_heads):\n",
    "        super(BERT,self).__init__()\n",
    "        self.encoder=Encoder(max_inp_len,inp_vocab_size,d_model,n_layers,n_heads)\n",
    "        \n",
    "    def call(self,inputs,mask=None):\n",
    "        output=self.encoder(inputs,mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13e383c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =Tokenizer(oov_token=\"<OOV>\")\n",
    "sentences = [pair for pair in combined_sentences]\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "def tokenize_and_mask(combined_pairs, tokenizer, mask_prob=0.15):\n",
    "    tokenized_pairs = []\n",
    "    segment_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for combined_pair in combined_pairs:\n",
    "        # Tokenize combined sentence pair\n",
    "        tokens = tokenizer.texts_to_sequences([combined_pair])[0]\n",
    "        \n",
    "        # Calculate segment IDs based on [SEP] tokens\n",
    "        sep_positions = [pos for pos, token in enumerate(tokens) if token == tokenizer.word_index[\"sep\"]]\n",
    "        seg_id = [0] * (sep_positions[0] + 1) + [1] * (len(tokens) - sep_positions[0] - 1)\n",
    "        \n",
    "        \n",
    "        # Masking\n",
    "        num_tokens = len(tokens)\n",
    "        num_masked = int(num_tokens * mask_prob)\n",
    "        masked_indices = random.sample(range(1, num_tokens - 1), num_masked)\n",
    "        \n",
    "        masked_tokens = tokens.copy()\n",
    "        for idx in masked_indices:\n",
    "            if random.random() < 0.8:  # 80% of the time, replace with a random word from the vocabulary\n",
    "                masked_tokens[idx] = random.choice(list(tokenizer.word_index.values()))\n",
    "                \n",
    "            else:  # 20% of the time, keep the token unchanged\n",
    "                pass\n",
    "                \n",
    "           \n",
    "            #if random.random() < 0.8:  # 80% of the time, replace with [MASK]\n",
    "                #masked_tokens[idx] = tokenizer.word_index['[MASK]']\n",
    "                \n",
    "            #elif random.random() < 0.5:  # 10% of the time, replace with random word\n",
    "                #masked_tokens[idx] = random.choice(list(tokenizer.word_index.values()))\n",
    "        \n",
    "        # Create attention mask\n",
    "        attn_mask = [1] * len(masked_tokens)\n",
    "        \n",
    "        tokenized_pairs.append(masked_tokens)\n",
    "        segment_ids.append(seg_id)\n",
    "        attention_masks.append(attn_mask)\n",
    "    \n",
    "    return tokenized_pairs, segment_ids, attention_masks\n",
    "\n",
    "tokenized_pairs, segment_ids, attention_masks = tokenize_and_mask(combined_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff241606",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(tokens) for tokens in tokenized_pairs)\n",
    "padded_pairs =pad_sequences(tokenized_pairs, maxlen=max_length, padding='post')\n",
    "#segment_ids =pad_sequences(segment_ids, maxlen=max_length, padding='post')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
