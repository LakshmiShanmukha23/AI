{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c450048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6c3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b58036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,GRU,Dense,Embedding,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8a3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119bc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "edab3473",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "data_file = open('spa.txt', encoding='utf-8')\n",
    "\n",
    "count = 0\n",
    "for line in data_file:\n",
    "    count += 1\n",
    "    if count > 7000:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    ip, temp_op, extra = line.rstrip().split('\\t')\n",
    "    op = temp_op\n",
    "    inputs.append(ip)\n",
    "    outputs.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6a2e4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = []\n",
    "outputs1 = []\n",
    "\n",
    "data_file = open('spa.txt', encoding='utf-8')\n",
    "\n",
    "count1 = 4000\n",
    "for line in data_file:\n",
    "    count1 += 1\n",
    "    if count1 > 4200:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    ip1, temp_op1, extra1 = line.rstrip().split('\\t')\n",
    "    op1 = temp_op1\n",
    "    inputs1.append(ip)\n",
    "    outputs1.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7c4b993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=[sentence.lower() for sentence in inputs1]\n",
    "outputs1=[sentence.lower() for sentence in outputs1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "91e7358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[sentence.lower() for sentence in inputs]\n",
    "outputs=[sentence.lower() for sentence in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "42dab836",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [\"<start>\"+\" \"+sentence+\" \"+\"<end>\" for sentence in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "705ee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = [\"<start>\"+\" \"+sentence+\" \"+\"<end>\" for sentence in outputs1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b7964c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnglishTokenizer=Tokenizer()\n",
    "EnglishTokenizer.fit_on_texts(inputs)\n",
    "inp_sequences=EnglishTokenizer.texts_to_sequences(inputs)\n",
    "max_inp_len=max(len(i) for i in inp_sequences)\n",
    "src_sequences=pad_sequences(inp_sequences,maxlen=max_inp_len,padding=\"post\")\n",
    "Englishword2index=EnglishTokenizer.word_index\n",
    "Englishindex2word=EnglishTokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "43daecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inp_sequences=EnglishTokenizer.texts_to_sequences(inputs1)\n",
    "test_inp_sequences=pad_sequences(test_inp_sequences,maxlen=max_inp_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "69febf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpanishTokenizer=Tokenizer()\n",
    "SpanishTokenizer.fit_on_texts(outputs)\n",
    "op_sequences=SpanishTokenizer.texts_to_sequences(outputs)\n",
    "max_tar_len=max(len(i) for i in op_sequences)\n",
    "tar_sequences=pad_sequences(op_sequences,maxlen=max_tar_len,padding=\"post\")\n",
    "Spanishword2index=SpanishTokenizer.word_index\n",
    "Spanishindex2word=SpanishTokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3af21ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_sequences=SpanishTokenizer.texts_to_sequences(outputs1)\n",
    "test_out_sequences=pad_sequences(test_out_sequences,maxlen=max_tar_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1676c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_vocab_size: 1807\n",
      "tar_vocab_size: 3913\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size=len(Englishword2index)+1\n",
    "trg_vocab_size=len(Spanishword2index)+1\n",
    "print(\"src_vocab_size:\",src_vocab_size)\n",
    "print(\"tar_vocab_size:\",trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "15db014e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 5), (200, 10))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inp_sequences.shape,test_out_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4c263204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_inp_len: 5\n",
      "max_tar_len: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"max_inp_len:\",max_inp_len)\n",
    "print(\"max_tar_len:\",max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7a814536",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_units=100\n",
    "embed_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acbc6b",
   "metadata": {},
   "source": [
    "## Word Embedding(Glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "76437dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray, zeros\n",
    "\n",
    "embeddings_dict = dict()\n",
    "\n",
    "glove_file = open('glove.6B.100d.txt', encoding='utf8')\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vector\n",
    "\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((src_vocab_size,embed_size))\n",
    "\n",
    "for word, index in Englishword2index.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4a9247b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1807, 100)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10bbbfa",
   "metadata": {},
   "source": [
    "## Bahdanau Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bb271f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query,values=inputs\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score1=self.W1(query_with_time_axis)\n",
    "        score2=self.W2(values)\n",
    "        combined_score=tf.nn.tanh(score1 + score2)\n",
    "        score = self.V(combined_score)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce6a20",
   "metadata": {},
   "source": [
    "## Encoder Decoder Architecture with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ee55e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(tf.keras.Model):\n",
    "    def __init__(self,max_inp_len,max_tar_len,inp_vocab_size,tar_vocab_size,gru_units,embed_size,embedding_matrix):\n",
    "        super(EncoderDecoder,self).__init__()\n",
    "        self.encoder_embed=Embedding(inp_vocab_size,embed_size,input_length=max_inp_len,weights=[embedding_matrix])\n",
    "        \n",
    "        self.encoder_gru=Bidirectional(GRU(gru_units,return_sequences=True,return_state=True))\n",
    "        self.encoder_fc=Dense(gru_units)\n",
    "        \n",
    "        self.decoder_embed=Embedding(tar_vocab_size,embed_size,input_length=max_tar_len)\n",
    "        self.decoder_gru=GRU(gru_units,return_sequences=True,return_state=True)\n",
    "        self.decoder_fc=Dense(tar_vocab_size,activation=\"softmax\")\n",
    "        self.attention=BahdanauAttention(gru_units)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        encoder_input,decoder_input=inputs\n",
    "        encoder_embed=self.encoder_embed(encoder_input)\n",
    "        encoder_op,forward,backward=self.encoder_gru(encoder_embed)\n",
    "        hidden = tf.tanh(self.encoder_fc(tf.concat([forward,backward], axis = -1)))\n",
    "        \n",
    "\n",
    "        decoder_embed=self.decoder_embed(decoder_input)\n",
    "        context_vector=self.attention([hidden,encoder_op])\n",
    "        context_vector=tf.expand_dims(context_vector,1)\n",
    "        context_vector=tf.tile(context_vector,[1,tf.shape(decoder_embed)[1],1])\n",
    "        encoder_op=tf.transpose(encoder_op,perm=(0,2,1))\n",
    "        decoder_combined=tf.matmul(context_vector,encoder_op)\n",
    "                \n",
    "        \n",
    "        weighted=tf.concat([decoder_embed, context_vector],axis=2)\n",
    "        \n",
    "        decoder_op,_=self.decoder_gru(weighted,initial_state=hidden)\n",
    "        \n",
    "        ouput=tf.concat([decoder_op,decoder_combined,decoder_embed],axis=2)\n",
    "        \n",
    "        dec_op=self.decoder_fc(ouput)\n",
    "        \n",
    "        return dec_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "365be663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=EncoderDecoder(max_inp_len,max_tar_len,src_vocab_size,trg_vocab_size,gru_units,embed_size,embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "270e1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e1d3d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_one_hot=tf.one_hot(tar_sequences,depth=trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "49536c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 74s 132ms/step - loss: 2.3252 - accuracy: 0.7181\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 29s 130ms/step - loss: 1.1269 - accuracy: 0.8628\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 30s 135ms/step - loss: 0.8224 - accuracy: 0.8990\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 28s 128ms/step - loss: 0.6116 - accuracy: 0.9253\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 29s 134ms/step - loss: 0.4502 - accuracy: 0.9438\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 27s 122ms/step - loss: 0.3242 - accuracy: 0.9578\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 28s 126ms/step - loss: 0.2255 - accuracy: 0.9682\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 27s 122ms/step - loss: 0.1502 - accuracy: 0.9809\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 26s 118ms/step - loss: 0.0939 - accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 26s 118ms/step - loss: 0.0524 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17ac7ce8280>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([src_sequences,tar_sequences],tar_one_hot,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8180100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     multiple                  180700    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  multiple                  121200    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_43 (Dense)            multiple                  20100     \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     multiple                  391300    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 multiple                  120600    \n",
      "                                                                 \n",
      " dense_44 (Dense)            multiple                  806078    \n",
      "                                                                 \n",
      " bahdanau_attention_13 (Bah  multiple                  30301     \n",
      " danauAttention)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1670279 (6.37 MB)\n",
      "Trainable params: 1670279 (6.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e1797d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one_hot=tf.one_hot(test_out_sequences,depth=trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "52ef7e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 52ms/step - loss: 0.0367 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate([test_inp_sequences,test_out_sequences],test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c49a30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_english_text = \"what is my name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0976c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_english_text=new_english_text+\" \"+\"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0ef06e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=EnglishTokenizer.texts_to_sequences([new_english_text])\n",
    "sample=pad_sequences(sample,maxlen=max_inp_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00852a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  60,    5,   26, 1120,    0]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f387383f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'todo'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spanishindex2word[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "23eac9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 6, 1\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [174]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m tar_seq1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[Spanishword2index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]]])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_tar_len):\n\u001b[1;32m----> 5\u001b[0m     translated1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_seq1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(translated1[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :])\n\u001b[0;32m      7\u001b[0m     translated_text \u001b[38;5;241m=\u001b[39m Spanishindex2word[p]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1943\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1944\u001b[0m         label,\n\u001b[0;32m   1945\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1946\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1947\u001b[0m         ),\n\u001b[0;32m   1948\u001b[0m     )\n\u001b[0;32m   1949\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1950\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 6, 1\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "trans = []\n",
    "tar_seq1 = np.array([[Spanishword2index['start']]])\n",
    "\n",
    "for i in range(max_tar_len):\n",
    "    translated1 = model.predict([sample, tar_seq1])\n",
    "    p = np.argmax(translated1[0, 0, :])\n",
    "    translated_text = Spanishindex2word[p]\n",
    "    trans.append(translated_text)\n",
    "    tar_seq1 = np.array([[p]])  \n",
    "    \n",
    "    sample = np.append(sample, p)\n",
    "    \n",
    "    if translated_text == '<end>': \n",
    "        break\n",
    "\n",
    "print(\"Translated sentence:\")\n",
    "print(\" \".join(trans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "39a93040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Translated sentence:\n",
      "todo todo todo todo todo todo todo todo todo todo\n"
     ]
    }
   ],
   "source": [
    "trans = []\n",
    "tar_seq1 = np.array([[Spanishword2index['todo']]])\n",
    "\n",
    "for i in range(max_tar_len):\n",
    "    translated1 = model.predict([sample, tar_seq1])\n",
    "    p = np.argmax(translated1[0, 0, :])\n",
    "    translated_text = Spanishindex2word[p]\n",
    "    trans.append(translated_text)\n",
    "    tar_seq1 = np.array([[p]]) \n",
    "    if translated_text == 'end': \n",
    "        break\n",
    "\n",
    "print(\"Translated sentence:\")\n",
    "print(\" \".join(trans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "78226695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a691e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs=Input(shape=(max_inp_len,))\n",
    "encoder_embed=model.layers[0](encoder_inputs)\n",
    "encoder_op,forward,backward=model.layers[1](encoder_embed)\n",
    "hidden=tf.nn.tanh(model.layers[2]((tf.concat([forward,backward], axis = -1))))\n",
    "encoder_model=Model(encoder_inputs,[encoder_op,hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f4608b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 4, 100)               97800     ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  [(None, 4, 200),             121200    ['embedding[1][0]']           \n",
      " al)                          (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " tf.concat_11 (TFOpLambda)   (None, 200)                  0         ['bidirectional[1][1]',       \n",
      "                                                                     'bidirectional[1][2]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100)                  20100     ['tf.concat_11[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.tanh_1 (TFOpLambda  (None, 100)                  0         ['dense[1][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 239100 (933.98 KB)\n",
      "Trainable params: 239100 (933.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c2db8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_embed: (None, 9, 100)\n",
      "context_vector: (None, 9, 4)\n",
      "encoder_op: (None, 4, 200)\n",
      "decoder_combined: (None, 9, 200)\n",
      "weighted: (None, 9, 104)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"gru_1\" (type GRU).\n\nDimensions must be equal, but are 104 and 300 for '{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](strided_slice_1, kernel)' with input shapes: [?,104], [300,300].\n\nCall arguments received by layer \"gru_1\" (type GRU):\n  • inputs=['tf.Tensor(shape=(None, 9, 104), dtype=float32)', 'tf.Tensor(shape=(None, 100), dtype=float32)']\n  • mask=None\n  • training=None\n  • initial_state=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [112]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m weighted\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconcat([decoder_embed, context_vector],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted:\u001b[39m\u001b[38;5;124m\"\u001b[39m,weighted\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 15\u001b[0m decoder_op,_\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_op:\u001b[39m\u001b[38;5;124m\"\u001b[39m,decoder_op\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     17\u001b[0m ouput\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconcat([decoder_op,decoder_combined,decoder_embed],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py:615\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m full_input_spec\n\u001b[1;32m--> 615\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(full_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    616\u001b[0m \u001b[38;5;66;03m# Remove the additional_specs from input spec and keep the rest. It\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# is important to keep since the input spec was populated by\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;66;03m# build(), and will be reused in the stateful=True.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:2465\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   2463\u001b[0m     out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39msparse_dense_matmul(x, y)\n\u001b[0;32m   2464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2465\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"gru_1\" (type GRU).\n\nDimensions must be equal, but are 104 and 300 for '{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](strided_slice_1, kernel)' with input shapes: [?,104], [300,300].\n\nCall arguments received by layer \"gru_1\" (type GRU):\n  • inputs=['tf.Tensor(shape=(None, 9, 104), dtype=float32)', 'tf.Tensor(shape=(None, 100), dtype=float32)']\n  • mask=None\n  • training=None\n  • initial_state=None"
     ]
    }
   ],
   "source": [
    "decoder_inputs=Input(shape=(max_tar_len,))\n",
    "decoder_embed=model.layers[3](decoder_inputs)\n",
    "print(\"decoder_embed:\",decoder_embed.shape)\n",
    "attention=BahdanauAttention(gru_units)\n",
    "context_vector=attention([hidden,encoder_op])\n",
    "context_vector=tf.expand_dims(context_vector,1)\n",
    "context_vector=tf.tile(context_vector,[1,tf.shape(decoder_embed)[1],1])\n",
    "print(\"context_vector:\",context_vector.shape)\n",
    "encoder_op=tf.transpose(encoder_op,perm=(0,2,1))\n",
    "print(\"encoder_op:\",encoder_op.shape)\n",
    "decoder_combined=tf.matmul(context_vector,encoder_op)\n",
    "print(\"decoder_combined:\",decoder_combined.shape)\n",
    "weighted=tf.concat([decoder_embed, context_vector],axis=2)\n",
    "print(\"weighted:\",weighted.shape)\n",
    "decoder_op,_=model.layers[4](weighted,initial_state=hidden)\n",
    "print(\"decoder_op:\",decoder_op.shape)\n",
    "ouput=tf.concat([decoder_op,decoder_combined,decoder_embed],axis=2)\n",
    "print(\"ouput:\",ouput.shape)\n",
    "dec_op=model.layers[5](ouput)\n",
    "print(\"dec_op:\",dec_ouput.shape)\n",
    "\n",
    "decoder_model=Model([decoder_inputs,encoder_op,hidden],dec_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d508b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdecoder_model\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoder_model' is not defined"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f58cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spanishword2index[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f281438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "[[36]]\n"
     ]
    }
   ],
   "source": [
    "trans=[]\n",
    "for i in range(max_tar_len):\n",
    "    translated1= model.predict([sample ,tar_seq1])\n",
    "    p=np.argmax(translated1[0,0,:])\n",
    "    translated_text=Spanishindex2word[p]\n",
    "    trans.append(translated_text)\n",
    "    tar_seq1=np.array([[Spanishword2index[translated_text]]])\n",
    "    print(tar_seq1)\n",
    "    trans.append(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db895962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es', '¿es']\n"
     ]
    }
   ],
   "source": [
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bf361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f88988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "translated1= model.predict([sample ,tar_seq1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ad97c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.argmax(translated1[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "745143d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2223)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57efc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=1.0864681e-05\n",
    "for i in translated1[0,0,:]:\n",
    "    if i>count:\n",
    "        count=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8cf25923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spanishindex2word[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b112df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translatedtext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19333e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Englishword2index[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d061e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
