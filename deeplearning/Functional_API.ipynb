{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1892d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1472c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc395319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f33e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895a43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179a5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f981de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_texts = [\n",
    "    \"I love natural language processing.\",\n",
    "    \"TensorFlow is a powerful framework.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"This is an example text.\",\n",
    "    \"Neural networks are amazing.\",\n",
    "    \"AI is the future of technology.\"\n",
    "]\n",
    "\n",
    "# French example sentences (translations of English sentences)\n",
    "french_texts = [\n",
    "    \"J'adore le traitement du langage naturel.\",\n",
    "    \"TensorFlow est un cadre puissant.\",\n",
    "    \"L'apprentissage automatique est fascinant.\",\n",
    "    \"Ceci est un exemple de texte.\",\n",
    "    \"Les r√©seaux neuronaux sont incroyables.\",\n",
    "    \"L'IA est l'avenir de la technologie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56cb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_texts=[\"<start>\"+\" \"+sentence+\" \"+\"<end>\" for sentence in french_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2119e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "EnglishTokenizer=Tokenizer(oov_token=\"<UNK>\")\n",
    "EnglishTokenizer.fit_on_texts(english_texts)\n",
    "src_sentences=EnglishTokenizer.texts_to_sequences(english_texts)\n",
    "src_max_len=max(len(i) for i in src_sentences)\n",
    "print(src_max_len)\n",
    "src_input_sent=pad_sequences(src_sentences,maxlen=src_max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8a5dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "FrenchTokenizer=Tokenizer(oov_token=\"<UNK>\")\n",
    "FrenchTokenizer.fit_on_texts(french_texts)\n",
    "trg_sentences=FrenchTokenizer.texts_to_sequences(french_texts)\n",
    "trg_max_len=max(len(i) for i in trg_sentences)\n",
    "print(trg_max_len)\n",
    "trg_input_sent=pad_sequences(trg_sentences,maxlen=trg_max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247345ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 8), (6, 6))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_input_sent.shape,src_input_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44fa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "English_word2text=EnglishTokenizer.word_index\n",
    "French_word2text=FrenchTokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02663f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size=len(English_word2text)+1\n",
    "trg_vocab_size=len(French_word2text)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539d8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=10\n",
    "lstm_units=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45f9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input=Input(shape=(src_max_len,))\n",
    "encoder_embedded=Embedding(src_vocab_size,dim,trainable=True)\n",
    "encoder_embed=encoder_embedded(encoder_input)\n",
    "encoder_lstm=LSTM(lstm_units,return_sequences=True,return_state=True)\n",
    "encoder_output,state_h,state_c=encoder_lstm(encoder_embed)\n",
    "\n",
    "decoder_input=Input(shape=(trg_max_len,))\n",
    "decoder_embedded=Embedding(trg_vocab_size,dim,trainable=True)\n",
    "decoder_embed=decoder_embedded(decoder_input)\n",
    "decoder_lstm=LSTM(lstm_units,return_sequences=True,return_state=True)\n",
    "decoder_output,state_h1,state_c1=decoder_lstm(decoder_embed,initial_state=[state_h,state_c])\n",
    "decoder_dense=Dense(trg_vocab_size,activation=\"softmax\")\n",
    "decoder_output=decoder_dense(decoder_output)\n",
    "\n",
    "model=Model([encoder_input,decoder_input],[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b74c0164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)       [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)       [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)     (None, 6, 10)                280       ['input_11[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, 8, 10)                310       ['input_12[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               [(None, 6, 5),               320       ['embedding_8[0][0]']         \n",
      "                              (None, 5),                                                          \n",
      "                              (None, 5)]                                                          \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               [(None, 8, 5),               320       ['embedding_9[0][0]',         \n",
      "                              (None, 5),                             'lstm_8[0][1]',              \n",
      "                              (None, 5)]                             'lstm_8[0][2]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 8, 31)                186       ['lstm_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1416 (5.53 KB)\n",
      "Trainable params: 1416 (5.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "377dbfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.7,clipnorm=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64985831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5524055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_one_hot=tf.one_hot(trg_input_sent,depth=trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30818577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 8, 31])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088dcd59",
   "metadata": {},
   "source": [
    "## Training(Teacher-Forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58e2eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb0183ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_function(targets, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aaf13089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.5395\n",
      "Epoch 2/10 - Loss: 0.5833\n",
      "Epoch 3/10 - Loss: 0.6348\n",
      "Epoch 4/10 - Loss: 0.6084\n",
      "Epoch 5/10 - Loss: 1.1494\n",
      "Epoch 6/10 - Loss: 0.8982\n",
      "Epoch 7/10 - Loss: 0.7278\n",
      "Epoch 8/10 - Loss: 0.6401\n",
      "Epoch 9/10 - Loss: 1.4008\n",
      "Epoch 10/10 - Loss: 0.8916\n"
     ]
    }
   ],
   "source": [
    "batch_size=3\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    steps_per_epoch = src_max_len // batch_size\n",
    "\n",
    "    for step in range(steps_per_epoch):\n",
    "        start = step * batch_size\n",
    "        end = (step + 1) * batch_size\n",
    "\n",
    "        batch_inputs = src_input_sent[start:end]\n",
    "        batch_targets = trg_input_sent[start:end]\n",
    "        loss = train_step([batch_inputs,batch_targets],batch_targets)\n",
    "        total_loss += loss\n",
    "\n",
    "    average_loss = total_loss / steps_per_epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de6169",
   "metadata": {},
   "source": [
    "## fit method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26d1ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9601 - accuracy: 0.7083\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8718 - accuracy: 0.7292\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8257 - accuracy: 0.7292\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7193 - accuracy: 0.7292\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6694 - accuracy: 0.7708\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6379 - accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6063 - accuracy: 0.7708\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5745 - accuracy: 0.8125\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5458 - accuracy: 0.7708\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5371 - accuracy: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b7e14f4a30>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([src_input_sent,trg_input_sent],trg_one_hot,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92a2c8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ce27bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_english_texts = [\n",
    "    \"I like deep learning.\",\n",
    "    \"AI is changing the world.\",\n",
    "    \"natural language processing is exciting.\"\n",
    "]\n",
    "\n",
    "test_french_texts = [\n",
    "    \"J'aime l'apprentissage profond.\",\n",
    "    \"L'IA change le monde.\",\n",
    "    \"Le traitement du langage naturel est passionnant.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55bd8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src_sentences=EnglishTokenizer.texts_to_sequences([test_english_texts])\n",
    "test_trg_sentences=FrenchTokenizer.texts_to_sequences([test_french_texts])\n",
    "\n",
    "test_src_padding=pad_sequences(test_src_sentences,maxlen=src_max_len,padding=\"post\")\n",
    "test_tar_padding=pad_sequences(test_trg_sentences,maxlen=trg_max_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a98f1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 4.1948 - accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate([test_src_padding,test_tar_padding],tf.one_hot(test_tar_padding,depth=trg_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84215f1",
   "metadata": {},
   "source": [
    "## Inference(Prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61549e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "src=\"natural language processing\"\n",
    "trg=np.zeros((1,1))\n",
    "trg[0,0]=French_word2text[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e832c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=EnglishTokenizer.texts_to_sequences([src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1966c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_src_padding=pad_sequences(new,maxlen=src_max_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "300c0368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6, 7, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_src_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "878b84e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "output_sent=model.predict([new_src_padding,trg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "637b1641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.22221070e-06, 6.04132083e-06, 9.02282774e-01, 3.21875305e-05,\n",
       "         1.94454137e-02, 1.72299275e-03, 1.66824926e-02, 8.45050719e-03,\n",
       "         2.53484264e-04, 3.57941724e-03, 1.78835558e-06, 2.16635417e-05,\n",
       "         2.81908922e-03, 1.16851786e-03, 6.72145747e-04, 6.60289970e-06,\n",
       "         5.49640926e-03, 4.64118831e-03, 4.88242926e-03, 5.69077255e-03,\n",
       "         2.40993500e-03, 2.35546287e-03, 3.81117105e-04, 8.97551712e-04,\n",
       "         3.36478843e-06, 5.80939988e-04, 1.40836276e-03, 3.90062225e-04,\n",
       "         7.30626334e-06, 2.41539720e-03, 1.12923635e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd4512c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_french_text = FrenchTokenizer.sequences_to_texts(output_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5af22bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_french_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6af3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_input,[encoder_output,state_h,state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cddfc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 6, 10)             280       \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               [(None, 6, 5),            320       \n",
      "                              (None, 5),                         \n",
      "                              (None, 5)]                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600 (2.34 KB)\n",
      "Trainable params: 600 (2.34 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0fe7e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model=Model([decoder_input,[state_h,state_c]],[decoder_output,state_h1,state_c1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0252f442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)       [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, 8, 10)                310       ['input_12[0][0]']            \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)       [(None, 5)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)       [(None, 5)]                  0         []                            \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               [(None, 8, 5),               320       ['embedding_9[2][0]',         \n",
      "                              (None, 5),                             'input_15[0][0]',            \n",
      "                              (None, 5)]                             'input_16[0][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 8, 31)                186       ['lstm_9[2][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 816 (3.19 KB)\n",
      "Trainable params: 816 (3.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251140c",
   "metadata": {},
   "source": [
    "## Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "abc25a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_sequence(input_seq):\n",
    "    input_seq=np.expand_dims(input_seq,axis=0)\n",
    "    encoder_output, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.array([[French_word2text['start']]])\n",
    "    output_seq = []\n",
    "    stop_condition=False\n",
    "    while not stop_condition:\n",
    "        decoder_output, state_h1, state_c1 = decoder_model.predict([target_seq,[state_h, state_c]])\n",
    "\n",
    "        # Get the next token index (greedy decoding)\n",
    "        sampled_token_index = np.argmax(decoder_output[0, 0, :])\n",
    "        if sampled_token_index ==0:\n",
    "            break\n",
    "        if sampled_token_index == French_word2text['end'] or len(output_seq) >= trg_max_len- 1:\n",
    "            stop_condition=True\n",
    "\n",
    "        output_seq.append(sampled_token_index)\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        state_h,state_c=state_h1,state_c1\n",
    "\n",
    "    return output_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f84638dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_english_texts = [\n",
    "    \"I like deep learning.\",\n",
    "    \"AI is changing the world.\",\n",
    "    \"natural language processing is exciting.\"\n",
    "]\n",
    "\n",
    "test_french_texts = [\n",
    "    \"J'aime l'apprentissage profond.\",\n",
    "    \"L'IA change le monde.\",\n",
    "    \"Le traitement du langage naturel est passionnant.\"\n",
    "]\n",
    "\n",
    "test_english_sequences = EnglishTokenizer.texts_to_sequences(test_english_texts)\n",
    "test_french_sequences = FrenchTokenizer.texts_to_sequences(test_french_texts)\n",
    "\n",
    "test_english_padded_sequences = pad_sequences(test_english_sequences, maxlen=src_max_len)\n",
    "test_french_padded_sequences = pad_sequences(test_french_sequences, maxlen=trg_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11011dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c896c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 1s 884ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "seq_gred=greedy_decode_sequence(test_english_padded_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa35c7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 25, 25, 25, 25, 25, 25, 25]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_gred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "017f8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "French_text2word=FrenchTokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92662b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start sont sont sont sont sont sont sont '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=\"\"\n",
    "for i in seq_gred:\n",
    "    m+=French_text2word[i]+\" \"\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "feb1e6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"L'IA change le monde.\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_french_texts[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
