{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18e5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc51e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SENTENCES = 20000 \n",
    "MAX_NUM_WORDS = 20000 \n",
    "MAX_SENT_LEN = 50\n",
    "\n",
    "EMBEDDING_SIZE = 100\n",
    "\n",
    "GRU_NEURONS = 100\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460b5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "data_file = open('spa.txt', encoding='utf-8')\n",
    "\n",
    "count = 0\n",
    "for line in data_file:\n",
    "    count += 1\n",
    "    if count > NUM_SENTENCES:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    ip, temp_op, extra = line.rstrip().split('\\t')\n",
    "    op= '<sos> '+ temp_op +' <eos>'\n",
    "    inputs.append(ip)\n",
    "    outputs.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6834cfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in input: 3769\n",
      "Length of longest sentence in input: 6\n",
      "Total unique words in output: 10553\n",
      "Length of longest sentence in output: 14\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(inputs)\n",
    "\n",
    "inputs_seq = input_tokenizer.texts_to_sequences(inputs)\n",
    "\n",
    "inputs_word2index = input_tokenizer.word_index\n",
    "print('Total unique words in input:', len(inputs_word2index))\n",
    "\n",
    "inputs_numwords = len(inputs_word2index)+1\n",
    "\n",
    "inputs_maxlen = max(len(s) for s in inputs_seq)\n",
    "print('Length of longest sentence in input:', inputs_maxlen)\n",
    "\n",
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "output_tokenizer.fit_on_texts(outputs)\n",
    "\n",
    "outputs_seq = output_tokenizer.texts_to_sequences(outputs)\n",
    "\n",
    "outputs_word2index = output_tokenizer.word_index\n",
    "print('Total unique words in output:', len(outputs_word2index))\n",
    "\n",
    "outputs_numwords = len(outputs_word2index)+1\n",
    "\n",
    "outputs_maxlen = max(len(s) for s in outputs_seq)\n",
    "print('Length of longest sentence in output:', outputs_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "378847b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences shape: (20000, 6)\n",
      "decoder_output_sequences shape: (20000, 14)\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_input_sequences = pad_sequences(inputs_seq, maxlen=inputs_maxlen)\n",
    "print('encoder_input_sequences shape:', encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(outputs_seq, maxlen=outputs_maxlen, padding='post')\n",
    "print('decoder_output_sequences shape:', decoder_output_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6309e4b",
   "metadata": {},
   "source": [
    "# BahdanauAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c088c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query,values=inputs\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score1=self.W1(query_with_time_axis)\n",
    "        score2=self.W2(values)\n",
    "        combined_score=tf.nn.tanh(score1 + score2)\n",
    "        score = self.V(combined_score)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136f5db",
   "metadata": {},
   "source": [
    "## ENCODER DECODER ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ffe5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,GRU,Dense,Embedding,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71bbb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce6d92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs=Input(shape=(inputs_maxlen,))\n",
    "encoder_embed=Embedding(inputs_numwords,EMBEDDING_SIZE)(encoder_inputs)\n",
    "encoder_gru=Bidirectional(GRU(GRU_NEURONS,return_sequences=True,return_state=True))\n",
    "encoder_op,forward,backward=encoder_gru(encoder_embed)\n",
    "encoder_dense=Dense(GRU_NEURONS)\n",
    "hidden=tf.nn.tanh(encoder_dense((tf.concat([forward,backward], axis = -1))))\n",
    "\n",
    "decoder_inputs=Input(shape=(outputs_maxlen,))\n",
    "decoder_embed=Embedding(outputs_numwords,EMBEDDING_SIZE)(decoder_inputs)\n",
    "attention=BahdanauAttention(GRU_NEURONS)\n",
    "context_vector=attention([hidden,encoder_op])\n",
    "context_vector=tf.expand_dims(context_vector,1)\n",
    "context_vector=tf.tile(context_vector,[1,tf.shape(decoder_embed)[1],1])\n",
    "encoder_op=tf.transpose(encoder_op,perm=(0,2,1))\n",
    "decoder_combined=tf.matmul(context_vector,encoder_op)\n",
    "weighted=tf.concat([decoder_embed, context_vector],axis=2)\n",
    "\n",
    "decoder_gru=GRU(GRU_NEURONS,return_sequences=True,return_state=True)\n",
    "decoder_op,_=decoder_gru(weighted,initial_state=hidden)\n",
    "\n",
    "ouput=tf.concat([decoder_op,decoder_combined,decoder_embed],axis=2)\n",
    "\n",
    "dec_op=Dense(outputs_numwords)(ouput)\n",
    "\n",
    "model=Model([encoder_inputs,decoder_inputs],dec_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da09944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 6, 100)               377000    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  [(None, 6, 200),             121200    ['embedding_5[0][0]']         \n",
      " onal)                        (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, 200)                  0         ['bidirectional_3[0][1]',     \n",
      "                                                                     'bidirectional_3[0][2]']     \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 100)                  20100     ['tf.concat_5[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 14, 100)              1055400   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.tanh_2 (TFOpLambda  (None, 100)                  0         ['dense_8[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bahdanau_attention_2 (Bahd  (None, 200)                  30301     ['tf.math.tanh_2[0][0]',      \n",
      " anauAttention)                                                      'bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOp  (3,)                         0         ['embedding_6[0][0]']         \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLamb  (None, 1, 200)               0         ['bahdanau_attention_2[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_2[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.tile_2 (TFOpLambda)      (None, 14, 200)              0         ['tf.expand_dims_2[0][0]',    \n",
      "                                                                     'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)    (None, 14, 300)              0         ['embedding_6[0][0]',         \n",
      "                                                                     'tf.tile_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (  (None, 200, 6)               0         ['bidirectional_3[0][0]']     \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " gru_5 (GRU)                 [(None, 14, 100),            120600    ['tf.concat_6[0][0]',         \n",
      "                              (None, 100)]                           'tf.math.tanh_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_2 (TFOpLa  (None, 14, 6)                0         ['tf.tile_2[0][0]',           \n",
      " mbda)                                                               'tf.compat.v1.transpose_2[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)    (None, 14, 206)              0         ['gru_5[0][0]',               \n",
      "                                                                     'tf.linalg.matmul_2[0][0]',  \n",
      "                                                                     'embedding_6[0][0]']         \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 14, 10554)            2184678   ['tf.concat_7[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3909279 (14.91 MB)\n",
      "Trainable params: 3909279 (14.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "299c9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs_onehot=tf.one_hot(decoder_input_sequences,depth=outputs_numwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd46c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846207e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "282/282 [==============================] - 275s 790ms/step - loss: 15.2765 - accuracy: 0.3668 - val_loss: 14.9198 - val_accuracy: 0.5875\n",
      "Epoch 2/5\n",
      "282/282 [==============================] - 227s 806ms/step - loss: 14.0270 - accuracy: 0.3557 - val_loss: 14.6355 - val_accuracy: 0.5823\n",
      "Epoch 3/5\n",
      "282/282 [==============================] - 211s 750ms/step - loss: 14.4851 - accuracy: 0.2130 - val_loss: 14.2101 - val_accuracy: 0.0172\n",
      "Epoch 4/5\n",
      "282/282 [==============================] - 255s 907ms/step - loss: 14.7729 - accuracy: 0.0983 - val_loss: 14.8152 - val_accuracy: 0.0384\n",
      "Epoch 5/5\n",
      "282/282 [==============================] - 222s 781ms/step - loss: 15.2178 - accuracy: 0.1309 - val_loss: 15.5198 - val_accuracy: 0.0720\n"
     ]
    }
   ],
   "source": [
    "trn = model.fit([encoder_input_sequences, decoder_input_sequences],\n",
    "               decoder_outputs_onehot, \n",
    "               batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ede8feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 6, 100)               377000    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  [(None, 6, 200),             121200    ['embedding_5[0][0]']         \n",
      " onal)                        (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, 200)                  0         ['bidirectional_3[0][1]',     \n",
      "                                                                     'bidirectional_3[0][2]']     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 100)                  20100     ['tf.concat_5[0][0]']         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (  (None, 200, 6)               0         ['bidirectional_3[0][0]']     \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.math.tanh_2 (TFOpLambda  (None, 100)                  0         ['dense_8[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 518300 (1.98 MB)\n",
      "Trainable params: 518300 (1.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, [encoder_op,hidden])\n",
    "print(encoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "669c1d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"bahdanau_attention_2\" (type BahdanauAttention).\n\nin user code:\n\n    File \"C:\\Users\\Rambabu\\AppData\\Local\\Temp\\ipykernel_7604\\3982687109.py\", line 12, in call  *\n        score2=self.W2(values)\n    File \"C:\\Users\\Rambabu\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Rambabu\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"dense_10\" is incompatible with the layer: expected axis -1 of input shape to have value 200, but received input with shape (None, 200, 6)\n\n\nCall arguments received by layer \"bahdanau_attention_2\" (type BahdanauAttention):\n  • inputs=[['tf.Tensor(shape=(None, 100), dtype=float32)'], 'tf.Tensor(shape=(None, 200, 6), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m decoder_input_word \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m      5\u001b[0m decoder_input_word_emb \u001b[38;5;241m=\u001b[39m Embedding(outputs_numwords,EMBEDDING_SIZE)(decoder_input_word)\n\u001b[1;32m----> 6\u001b[0m context_vector\u001b[38;5;241m=\u001b[39m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_input_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_op\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m context_vector\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mexpand_dims(context_vector,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m context_vector\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mtile(context_vector,[\u001b[38;5;241m1\u001b[39m,tf\u001b[38;5;241m.\u001b[39mshape(decoder_embed)[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7xr2nf5n.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     11\u001b[0m query_with_time_axis \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(query), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m score1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mW1, (ag__\u001b[38;5;241m.\u001b[39mld(query_with_time_axis),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 13\u001b[0m score2 \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m combined_score \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mtanh, (ag__\u001b[38;5;241m.\u001b[39mld(score1) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(score2),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     15\u001b[0m score \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mV, (ag__\u001b[38;5;241m.\u001b[39mld(combined_score),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"bahdanau_attention_2\" (type BahdanauAttention).\n\nin user code:\n\n    File \"C:\\Users\\Rambabu\\AppData\\Local\\Temp\\ipykernel_7604\\3982687109.py\", line 12, in call  *\n        score2=self.W2(values)\n    File \"C:\\Users\\Rambabu\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Rambabu\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"dense_10\" is incompatible with the layer: expected axis -1 of input shape to have value 200, but received input with shape (None, 200, 6)\n\n\nCall arguments received by layer \"bahdanau_attention_2\" (type BahdanauAttention):\n  • inputs=[['tf.Tensor(shape=(None, 100), dtype=float32)'], 'tf.Tensor(shape=(None, 200, 6), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "hidden = Input(shape=(GRU_NEURONS,))\n",
    "decoder_input_states = [hidden]\n",
    "\n",
    "decoder_input_word = Input(shape=(1,))\n",
    "decoder_input_word_emb = Embedding(outputs_numwords,EMBEDDING_SIZE)(decoder_input_word)\n",
    "context_vector=attention([decoder_input_states,encoder_op])\n",
    "context_vector=tf.expand_dims(context_vector,1)\n",
    "context_vector=tf.tile(context_vector,[1,tf.shape(decoder_embed)[1],1])\n",
    "encoder_op=tf.transpose(encoder_op,perm=(0,2,1))\n",
    "decoder_combined=tf.matmul(context_vector,encoder_op)\n",
    "weighted=tf.concat([decoder_embed, context_vector],axis=2)\n",
    "decoder_op,h=decoder_gru(weighted,initial_state=decoder_input_states)\n",
    "ouput=tf.concat([decoder_op,decoder_combined,decoder_embed],axis=2)\n",
    "\n",
    "dec_op=dec_op(ouput)\n",
    "decoder_states = [h]\n",
    "\n",
    "outputs = output_dense_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model([decoder_input_word]+[encoder_op,decoder_input_states], [outputs]+decoder_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
