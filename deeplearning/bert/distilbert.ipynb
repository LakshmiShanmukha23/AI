{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093b0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cbe9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be4885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dc4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8db8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cecf827798f481eb1d7a9b040de2000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305d4bbb6c59493fa9fbfd5744aa2b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier=pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692cbd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fdfaa2318241a1b6ef2fe6a88a7f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rambabu\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Rambabu\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\Rambabu\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\storage.py:233: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  return super().__getitem__(*args, **kwargs)\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d23528447942af962408d482b0b973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acf983046b54a75ae532ecec7f0d338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0426cecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bc6f3614f247dc9e607baed768e1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625bc130fde4461a82b9faddda35bd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be63219b531644c5890448dc2923e123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98670155fd584926b573b7985a86f57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29092945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abedc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c33838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding,Dense,LayerNormalization,Dropout,MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaca6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear,Embedding,LayerNorm,Dropout,Module,MultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0b1d5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_scaled_dot_product(query,key,value,mask=None):\n",
    "    dk=tf.shape(query)[-1]\n",
    "    key=tf.transpose(key,perm=(0,1,3,2))\n",
    "    score=tf.matmul(query,key)/np.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        score+=mask\n",
    "    attention_wts=tf.nn.softmax(score,axis=-1)\n",
    "    context_vector=tf.matmul(attention_wts,value)\n",
    "    return context_vector,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "39eef6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.random.random((1,8,4,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "9954d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfa,m=tf_scaled_dot_product(p,p,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "c6bf810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 8, 4, 64])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "120d2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62b5c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_scaled_dot_product(query,key,value,mask=None):\n",
    "    dk=query.size()[-1]\n",
    "    key=key.transpose(-1,-2)\n",
    "    score=query.matmul(key)/np.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        score+=mask\n",
    "    attention_wts=F.softmax(score,dim=-1)\n",
    "    context_vector=torch.matmul(attention_wts,value)\n",
    "    return score,context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ae32379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=torch.rand((1,8,4,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3fadac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "20f54645",
   "metadata": {},
   "outputs": [],
   "source": [
    "score,ta=torch_scaled_dot_product(q,q,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97ee6fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "337671c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.size(),score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "916d5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.full(score.size(),float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6e0ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask0=torch.triu(mask,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "69b234f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask0[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "09ecc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2=torch.tril(mask,diagonal=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "66c5f39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [-inf, 0., 0., 0.],\n",
       "        [-inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, -inf, 0.]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c513ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=tf.fill(score.size(),float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d8b04cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=tf.linalg.band_part(mask1,0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "3a8a040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[-inf, -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, -inf]], dtype=float32)>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "39ea302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.tril(torch.ones(score.size()),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "86d69e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "7fcf682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 8, 4, 4])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "4c54c733",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [1,8,4,4], then [], and else [1,8,4,1,4] must be broadcastable [Op:SelectV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [390]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores1\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask1\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-inf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   6655\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [1,8,4,4], then [], and else [1,8,4,1,4] must be broadcastable [Op:SelectV2] name: "
     ]
    }
   ],
   "source": [
    "scores1=tf.where(mask1!=0,float('-inf'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "904b4f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float64, numpy=\n",
       "array([[      -inf,       -inf,       -inf,       -inf],\n",
       "       [1.84327783,       -inf,       -inf,       -inf],\n",
       "       [1.97818566, 1.87336725,       -inf,       -inf],\n",
       "       [2.01660168, 1.82149627, 2.00311921,       -inf]])>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6a5a3cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float64, numpy=\n",
       "array([[      -inf,       -inf,       -inf,       -inf],\n",
       "       [1.84327783,       -inf,       -inf,       -inf],\n",
       "       [1.97818566, 1.87336725,       -inf,       -inf],\n",
       "       [2.01660168, 1.82149627, 2.00311921,       -inf]])>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "1aafe6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=score.masked_fill(mask==0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "245a81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7567,   -inf,   -inf,   -inf],\n",
       "        [2.2605, 2.9969,   -inf,   -inf],\n",
       "        [1.9832, 2.0995, 2.5692,   -inf],\n",
       "        [1.9208, 1.9373, 1.7918, 2.3374]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42055abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
